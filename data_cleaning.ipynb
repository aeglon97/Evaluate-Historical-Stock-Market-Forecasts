{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S&P 2019 Data Wrangling\n",
    "\n",
    "**by Marc Angelo Acebedo**\n",
    "\n",
    "## Table of Contents\n",
    "- [Introduction](#introduction)\n",
    "- [Data Wrangling](#wrangling)\n",
    "    - [Gather](#gather)\n",
    "    - [Assess](#assess)\n",
    "    - [Clean](#clean)\n",
    "    - [Store](#store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) Introduction <a id = \"introduction\">\n",
    "\n",
    "**Broad question:** How do price forecasts for each firm in the S&P 2019 Index compare to their corresponding actual prices?\n",
    "\n",
    "**Approach:** Analyze difference in means between average forecast EPS and average actual EPS for each firm.\n",
    "\n",
    "I will be analyzing quarterly price returns within the past 20 years for the firms present in the S&P 500 2019 Index.\n",
    "\n",
    "> At first, I wanted to analyze the forecasted vs. actual price earnings of the S&P in its entirety for the past 20 years. However, considering that firms continuously enter and leave stock indices every year, there would be varying levels of inconsistencies and marginal errors when comparing annual S&P returns alone. To combat this problem, I have isolated these two approaches:\n",
    "- Analyze the historical earnings of *only* the firms present in the S&P 2019 Index\n",
    "- Keep track of all firms that were present in the S&P for the past 20 years. Keep track of how many times each firm appeared in the Index and for those with the least count, analyze them individually on how they differ from the firms that stayed for longer.\n",
    "\n",
    "[TK] HEre is a breakdown of my final clean CSV's features, TK.csv.\n",
    "\n",
    "## II) Data Wrangling <a id=\"wrangling\"></a>\n",
    "\n",
    "To gather the data depicted under the `./data` folder, I used Bloomberg Excel functions.\n",
    "\n",
    "### A) Gather <a id = \"gather\"></a>\n",
    "> **APPROACH 1:** Focus on the firms that appear in the 2019 S&P Index and analyze their forecasted vs. actual price earnings for the last 20 years.\n",
    "\n",
    "To ensure consistency in analysis among multiple firms, I divide both the forecasted and actual price earning dates by *calendar period* instead of fiscal period. This is because fiscal period differs by firm whereas calendar period is consistent by dates. \n",
    "\n",
    "#### Through the Bloomberg Excel functions, I gathered four datasets with different purposes:\n",
    "\n",
    "- historical forecasted EPS\n",
    "- historical actual EPS\n",
    "- historical actual EOD price\n",
    "- historical forecasted EPS relying on terms\n",
    "\n",
    "---\n",
    "Before delving into the data, let's define what above terms:\n",
    "\n",
    "**EPS**\n",
    "\n",
    "> EPS stands for ***Estimated Price Earnings.*** The formal definition of EPS given by Investopedia is this:\n",
    "\n",
    "Earnings per share is the portion of a company's profit that is allocated to each outstanding share of a common stock, serving as an indicator of the company's financial health.\n",
    "\n",
    "In other words, the EPS is a portion of the company's **net income** after all of their dividends are paid off. Dividends are profits that are paid out to shareholders of the company. EPS is one of the most useful and valuable financial measurements because they ***determine a stock's worth.*** The higher the stock, the more the company can pay out dividends to its shareholders, and the more net profit they are determined to generate.\n",
    "\n",
    "$$ EPS = \\frac{Net Income - Preferred Dividends}{Weighted Average Common Shares Outstanding}\\$$\n",
    "\n",
    "**EOD**\n",
    "\n",
    "> EOD stands for the ***End of Day*** price. For any given day, the EOD marks the ***price at which the stock was valued*** at the end of the day's trading period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './data/'\n",
    "PATH_CLEAN = './data/clean/'\n",
    "PATH_CLEAN_AVGS = './data/clean/averages/'\n",
    "PATH_CLEAN_AVGS_SUB = './data/clean/averages/components/'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb\n",
    "\n",
    "from functools import reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data <a id = \"import\"></a>\n",
    "\n",
    "### Let's summarize the contents of the following DataFrames as we import them.\n",
    "> All DataFrames consist of the 505 firms found in the 2019 S&P Index with EPS and EOD data encompassing 20 years: from January 1999 until the December 2019.\n",
    "\n",
    "**Historic forecasted EPS**\n",
    "> According to Investopedia, consensus estimates is normally an average or median of all the forecasts from individual analysts tracking a particular stock. In this case, the consensus estimate is for ***EPS for each firm present in the index as of 2019.*** Forecasted EPS is calculated by ***quarterly earnings,*** usually by each firm's fiscal period. Estimates of quarterly earnings are published at the beginning of each quarterly period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historic forecasted EPS \n",
    "eps_fc = pd.read_csv(PATH + 'sp-eps-fc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term Forecasted</th>\n",
       "      <th>A UN Equity</th>\n",
       "      <th>AAL UW Equity</th>\n",
       "      <th>AAP UN Equity</th>\n",
       "      <th>AAPL UW Equity</th>\n",
       "      <th>ABBV UN Equity</th>\n",
       "      <th>ABC UN Equity</th>\n",
       "      <th>ABMD UW Equity</th>\n",
       "      <th>ABT UN Equity</th>\n",
       "      <th>ACN UN Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL UW Equity</th>\n",
       "      <th>XLNX UW Equity</th>\n",
       "      <th>XOM UN Equity</th>\n",
       "      <th>XRAY UW Equity</th>\n",
       "      <th>XRX UN Equity</th>\n",
       "      <th>XYL UN Equity</th>\n",
       "      <th>YUM UN Equity</th>\n",
       "      <th>ZBH UN Equity</th>\n",
       "      <th>ZION UW Equity</th>\n",
       "      <th>ZTS UN Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.622</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999Q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999Q3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999Q4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 506 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Term Forecasted  A UN Equity  AAL UW Equity  AAP UN Equity  AAPL UW Equity  \\\n",
       "0          1999Q1          NaN            NaN            NaN           0.025   \n",
       "1          1999Q2          NaN            NaN            NaN           0.020   \n",
       "2          1999Q3          NaN            NaN            NaN           0.023   \n",
       "3          1999Q4          NaN            NaN            NaN           0.016   \n",
       "4            00Q1          NaN            NaN            NaN           0.032   \n",
       "\n",
       "   ABBV UN Equity  ABC UN Equity  ABMD UW Equity  ABT UN Equity  \\\n",
       "0             NaN            NaN           -0.10          0.423   \n",
       "1             NaN            NaN           -0.13          0.420   \n",
       "2             NaN            NaN           -0.11          0.381   \n",
       "3             NaN            NaN             NaN          0.432   \n",
       "4             NaN            NaN             NaN          0.441   \n",
       "\n",
       "   ACN UN Equity  ...  XEL UW Equity  XLNX UW Equity  XOM UN Equity  \\\n",
       "0            NaN  ...          0.456           0.090          0.239   \n",
       "1            NaN  ...          0.213           0.090          0.264   \n",
       "2            NaN  ...          0.767           0.099          0.300   \n",
       "3            NaN  ...          0.432           0.124          0.386   \n",
       "4            NaN  ...          0.283           0.143          0.436   \n",
       "\n",
       "   XRAY UW Equity  XRX UN Equity  XYL UN Equity  YUM UN Equity  ZBH UN Equity  \\\n",
       "0           0.123            NaN            NaN          0.123            NaN   \n",
       "1           0.135            NaN            NaN          0.150            NaN   \n",
       "2           0.129            NaN            NaN          0.171            NaN   \n",
       "3           0.178            NaN            NaN          0.164            NaN   \n",
       "4           0.138            NaN            NaN          0.138            NaN   \n",
       "\n",
       "   ZION UW Equity  ZTS UN Equity  \n",
       "0           0.622            NaN  \n",
       "1           0.661            NaN  \n",
       "2           0.693            NaN  \n",
       "3           0.667            NaN  \n",
       "4           0.668            NaN  \n",
       "\n",
       "[5 rows x 506 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_fc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Historic actual EPS**\n",
    "> Unlike forecasted EPS, actual EPS are the real numbers denoting Earnings-per-Share for a singular firm. Historic actual EPS will be compared to forecasted EPS to draw correlations and comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historic actual EPS\n",
    "eps_act = pd.read_csv(PATH + 'sp-eps-act.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>A UN Equity</th>\n",
       "      <th>AAL UW Equity</th>\n",
       "      <th>AAP UN Equity</th>\n",
       "      <th>AAPL UW Equity</th>\n",
       "      <th>ABBV UN Equity</th>\n",
       "      <th>ABC UN Equity</th>\n",
       "      <th>ABMD UW Equity</th>\n",
       "      <th>ABT UN Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL UW Equity</th>\n",
       "      <th>XLNX UW Equity</th>\n",
       "      <th>XOM UN Equity</th>\n",
       "      <th>XRAY UW Equity</th>\n",
       "      <th>XRX UN Equity</th>\n",
       "      <th>XYL UN Equity</th>\n",
       "      <th>YUM UN Equity</th>\n",
       "      <th>ZBH UN Equity</th>\n",
       "      <th>ZION UW Equity</th>\n",
       "      <th>ZTS UN Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>1.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0975</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>2.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>1.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>1.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quarter  Year  A UN Equity  AAL UW Equity  AAP UN Equity  AAPL UW Equity  \\\n",
       "0      Q1  1999         0.16           0.99            NaN        0.040000   \n",
       "1      Q2  1999         0.35           1.76            NaN        0.035357   \n",
       "2      Q3  1999         0.30           1.86            NaN        0.050357   \n",
       "3      Q4  1999         0.32           1.89            NaN        0.024643   \n",
       "4      Q1  2000         0.29           0.89            NaN        0.040585   \n",
       "\n",
       "   ABBV UN Equity  ABC UN Equity  ABMD UW Equity  ABT UN Equity  ...  \\\n",
       "0             NaN         0.0925          -0.030           0.44  ...   \n",
       "1             NaN         0.1000          -0.145           0.42  ...   \n",
       "2             NaN         0.1075          -0.135           0.30  ...   \n",
       "3             NaN         0.0375          -0.080           0.43  ...   \n",
       "4             NaN         0.1050          -0.045           0.45  ...   \n",
       "\n",
       "   XEL UW Equity  XLNX UW Equity  XOM UN Equity  XRAY UW Equity  \\\n",
       "0           0.34          0.0000          0.210        0.123333   \n",
       "1           0.06          0.0975          0.285        0.133333   \n",
       "2           0.63          0.0325          0.315        0.130000   \n",
       "3           0.43          0.1300          0.600        0.180000   \n",
       "4           0.45          0.1650          0.500        0.140000   \n",
       "\n",
       "   XRX UN Equity  XYL UN Equity  YUM UN Equity  ZBH UN Equity  ZION UW Equity  \\\n",
       "0           1.64            NaN         0.1725            NaN            0.56   \n",
       "1           2.28            NaN         0.2900            NaN            0.60   \n",
       "2           1.96            NaN         0.3200            NaN            0.64   \n",
       "3           1.72            NaN         0.2375            NaN            0.49   \n",
       "4          -1.48            NaN         0.2025            NaN           -0.33   \n",
       "\n",
       "   ZTS UN Equity  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "\n",
       "[5 rows x 507 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_act.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Historic actual EOD**\n",
    "> Though this is not directly related to EPS data, EOD would be an interesting measure to use when generating intriguing visualizations and analyses. Who knows what visuals and conclusions I would arrive to with this measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historic actual EOD\n",
    "eod_act = pd.read_csv(PATH + 'sp-eod-act.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>A UN Equity</th>\n",
       "      <th>AAL UW Equity</th>\n",
       "      <th>AAP UN Equity</th>\n",
       "      <th>AAPL UW Equity</th>\n",
       "      <th>ABBV UN Equity</th>\n",
       "      <th>ABC UN Equity</th>\n",
       "      <th>ABMD UW Equity</th>\n",
       "      <th>ABT UN Equity</th>\n",
       "      <th>ACN UN Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL UW Equity</th>\n",
       "      <th>XLNX UW Equity</th>\n",
       "      <th>XOM UN Equity</th>\n",
       "      <th>XRAY UW Equity</th>\n",
       "      <th>XRX UN Equity</th>\n",
       "      <th>XYL UN Equity</th>\n",
       "      <th>YUM UN Equity</th>\n",
       "      <th>ZBH UN Equity</th>\n",
       "      <th>ZION UW Equity</th>\n",
       "      <th>ZTS UN Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/31/1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.2934</td>\n",
       "      <td>6.250</td>\n",
       "      <td>20.9504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.2813</td>\n",
       "      <td>35.2813</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>140.6214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.6284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.5000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/30/1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1859</td>\n",
       "      <td>6.875</td>\n",
       "      <td>20.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.6250</td>\n",
       "      <td>38.5625</td>\n",
       "      <td>9.6250</td>\n",
       "      <td>155.6057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.7297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.5000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/30/1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7462</td>\n",
       "      <td>7.750</td>\n",
       "      <td>16.4471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.7656</td>\n",
       "      <td>37.9688</td>\n",
       "      <td>7.5833</td>\n",
       "      <td>110.4883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.3591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.1250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/31/1999</td>\n",
       "      <td>52.0909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6843</td>\n",
       "      <td>18.375</td>\n",
       "      <td>16.2513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.4688</td>\n",
       "      <td>40.2813</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>59.7723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.9434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.1875</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/31/2000</td>\n",
       "      <td>70.0721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6388</td>\n",
       "      <td>20.250</td>\n",
       "      <td>15.7478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.8125</td>\n",
       "      <td>38.9063</td>\n",
       "      <td>9.4583</td>\n",
       "      <td>68.4994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 506 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  A UN Equity  AAL UW Equity  AAP UN Equity  AAPL UW Equity  \\\n",
       "0   3/31/1999          NaN            NaN            NaN          1.2835   \n",
       "1   6/30/1999          NaN            NaN            NaN          1.6540   \n",
       "2   9/30/1999          NaN            NaN            NaN          2.2612   \n",
       "3  12/31/1999      52.0909            NaN            NaN          3.6719   \n",
       "4   3/31/2000      70.0721            NaN            NaN          4.8504   \n",
       "\n",
       "   ABBV UN Equity  ABC UN Equity  ABMD UW Equity  ABT UN Equity  \\\n",
       "0             NaN         8.2934           6.250        20.9504   \n",
       "1             NaN         6.1859           6.875        20.3630   \n",
       "2             NaN         5.7462           7.750        16.4471   \n",
       "3             NaN         3.6843          18.375        16.2513   \n",
       "4             NaN         3.6388          20.250        15.7478   \n",
       "\n",
       "   ACN UN Equity  ...  XEL UW Equity  XLNX UW Equity  XOM UN Equity  \\\n",
       "0            NaN  ...            NaN         20.2813        35.2813   \n",
       "1            NaN  ...            NaN         28.6250        38.5625   \n",
       "2            NaN  ...            NaN         32.7656        37.9688   \n",
       "3            NaN  ...            NaN         45.4688        40.2813   \n",
       "4            NaN  ...            NaN         82.8125        38.9063   \n",
       "\n",
       "   XRAY UW Equity  XRX UN Equity  XYL UN Equity  YUM UN Equity  ZBH UN Equity  \\\n",
       "0          7.7500       140.6214            NaN        12.6284            NaN   \n",
       "1          9.6250       155.6057            NaN         9.7297            NaN   \n",
       "2          7.5833       110.4883            NaN         7.3591            NaN   \n",
       "3          7.8750        59.7723            NaN         6.9434            NaN   \n",
       "4          9.4583        68.4994            NaN         5.5839            NaN   \n",
       "\n",
       "   ZION UW Equity  ZTS UN Equity  \n",
       "0         66.5000            NaN  \n",
       "1         63.5000            NaN  \n",
       "2         55.1250            NaN  \n",
       "3         59.1875            NaN  \n",
       "4         41.6250            NaN  \n",
       "\n",
       "[5 rows x 506 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eod_act.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Historic forecasted EPS 3 months prior**\n",
    "> Instead of using forecast data collected at the beginning of the fiscal period, this feature contains EPS data projected 3 months before the current fiscal period. This is an interesting metric to see how differently forecasters make their predictions at different times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historic forecasted EPS 3-months prior\n",
    "eps_fc_terms = pd.read_csv(PATH + 'sp-eps-fc-terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Forecast Made</th>\n",
       "      <th>Term Forecasted</th>\n",
       "      <th>A UN Equity</th>\n",
       "      <th>AAL UW Equity</th>\n",
       "      <th>AAP UN Equity</th>\n",
       "      <th>AAPL UW Equity</th>\n",
       "      <th>ABBV UN Equity</th>\n",
       "      <th>ABC UN Equity</th>\n",
       "      <th>ABMD UW Equity</th>\n",
       "      <th>ABT UN Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL UW Equity</th>\n",
       "      <th>XLNX UW Equity</th>\n",
       "      <th>XOM UN Equity</th>\n",
       "      <th>XRAY UW Equity</th>\n",
       "      <th>XRX UN Equity</th>\n",
       "      <th>XYL UN Equity</th>\n",
       "      <th>YUM UN Equity</th>\n",
       "      <th>ZBH UN Equity</th>\n",
       "      <th>ZION UW Equity</th>\n",
       "      <th>ZTS UN Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/1/1999</td>\n",
       "      <td>00Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2000</td>\n",
       "      <td>00Q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/1/2000</td>\n",
       "      <td>00Q3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.803</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/1/2000</td>\n",
       "      <td>00Q4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/1/2000</td>\n",
       "      <td>01Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Forecast Made Term Forecasted  A UN Equity  AAL UW Equity  AAP UN Equity  \\\n",
       "0     10/1/1999            00Q1          NaN            NaN            NaN   \n",
       "1      1/1/2000            00Q2          NaN            NaN            NaN   \n",
       "2      4/1/2000            00Q3          NaN            NaN            NaN   \n",
       "3      7/1/2000            00Q4          NaN            NaN            NaN   \n",
       "4      9/1/2000            01Q1          NaN            NaN            NaN   \n",
       "\n",
       "   AAPL UW Equity  ABBV UN Equity  ABC UN Equity  ABMD UW Equity  \\\n",
       "0           0.030             NaN            NaN             NaN   \n",
       "1           0.026             NaN            NaN             NaN   \n",
       "2           0.029             NaN            NaN             NaN   \n",
       "3           0.032             NaN            NaN           -0.18   \n",
       "4           0.041             NaN            NaN           -0.09   \n",
       "\n",
       "   ABT UN Equity  ...  XEL UW Equity  XLNX UW Equity  XOM UN Equity  \\\n",
       "0          0.466  ...            NaN           0.143          0.398   \n",
       "1          0.437  ...            NaN           0.168          0.378   \n",
       "2          0.414  ...           0.84           0.189          0.425   \n",
       "3          0.477  ...           0.53           0.211          0.487   \n",
       "4          0.495  ...           0.40           0.259          0.475   \n",
       "\n",
       "   XRAY UW Equity  XRX UN Equity  XYL UN Equity  YUM UN Equity  ZBH UN Equity  \\\n",
       "0           0.140            NaN            NaN          0.144            NaN   \n",
       "1           0.153            NaN            NaN          0.184            NaN   \n",
       "2           0.149            NaN            NaN          0.218            NaN   \n",
       "3           0.200            NaN            NaN          0.244            NaN   \n",
       "4           0.158            NaN            NaN          0.178            NaN   \n",
       "\n",
       "   ZION UW Equity  ZTS UN Equity  \n",
       "0           0.777            NaN  \n",
       "1           0.790            NaN  \n",
       "2           0.803            NaN  \n",
       "3           0.777            NaN  \n",
       "4           0.750            NaN  \n",
       "\n",
       "[5 rows x 507 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_fc_terms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B) Assess <a id = \"assess\"></a>\n",
    "\n",
    "> The following DataFrames contain data for each firm across various dates. To account for all firm averages, my goal is to generate a CSV file where each row contains the firm average, with the features as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dfs = {'eps_fcast' : eps_fc,\n",
    "           'eps_actual' : eps_act,\n",
    "           'eod_actual' : eod_act,\n",
    "           'eps_fcast_terms' : eps_fc_terms}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Missing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast (84, 506)\n",
      "eps_actual (84, 507)\n",
      "eod_actual (84, 506)\n",
      "eps_fcast_terms (80, 507)\n"
     ]
    }
   ],
   "source": [
    "for key, df in dict_dfs.items():\n",
    "    print(key, df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We need to make sure the number of firms in each DataFrame is consistent.***\n",
    "\n",
    "---\n",
    "\n",
    "**Observation 1:** for `eps_fcast`, there are 505 firms encompassing 84 quarterly fiscal periods since 1999.\n",
    "\n",
    "> There are 506 columns: 1 column being `Term Forecast`, the rest firm names.\n",
    "\n",
    "**Observation 2:** for `eps_actual`, there are 505 firms encompassing 84 quarterly fiscal periods since 1999.\n",
    "\n",
    "> There are 507 columns: 2 columns being `Quarter` and `Year`, the rest firm names.\n",
    "\n",
    "**Observation 3:** for `eod_actual`, there are 505 firms encompassing 84 quarterly calendar periods since 1999.\n",
    "\n",
    "> There are 506 columns: 1 column being `date`, the rest firm names.\n",
    "\n",
    "**Observation 4:** for `eps_fcast_terms`, there are 505 firms encompassing 80 quarterly calendar periods since 1999.\n",
    "\n",
    "> There are 507 columns: 2 columns being `Forecast Made` and `Term Forecasted`, the rest firm names.\n",
    " \n",
    "Since there are only 80 quarterly calendar periods, that ***implies an entire year is missing.***\n",
    "\n",
    "**Observation 5:** For `eps_fcast`, `eps_actual`, and `eod_actual`, since there are 4 quarters in a year, 84 quarterly forecast periods equate to 21 years. This is correct since we are analyzing the years from 1999 until the end of 2019.\n",
    "\n",
    "### Most importantly, the number of firms across all DataFrames is consistent.\n",
    "\n",
    "----\n",
    "\n",
    "***Check which year is missing from `eps_fcast_terms`***.\n",
    "\n",
    "> Each **Term Forecasted** entry under `eps_fcast_terms` records the year with 2 digits, so Quarter 1 of the year 2000 becomes 00Q1.\n",
    "- isolate the first 2 characters to get the year\n",
    "- join a '20' in front of the string so 00 becomes 2000\n",
    "- list the number of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iterate over all years in eps_fcast_terms, append '20' in front of string\n",
    "list(map(lambda x: '20' + x, eps_fc_terms['Term Forecasted'].str[:2].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: The year 1999 is missing from `eps_fc_terms`. This makes sense because the start of the forecasting period would be in the last quarter of 1999, which is October. \n",
    "\n",
    "---\n",
    "\n",
    "### Check Nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# NaN in eps_fcast: 7055\n",
      "# NaN in eps_actual: 5021\n",
      "# NaN in eod_actual: 6921\n",
      "# NaN in eps_fcast_terms: 7080\n"
     ]
    }
   ],
   "source": [
    "for key, df in dict_dfs.items():\n",
    "    #display (row, column) per DataFrame\n",
    "    print('# NaN in {}: {}'.format(key, df.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** All four DataSets contain null values.\n",
    "> In order to combat this, we'll have to look at both the **number of rows** and **number of columns** with missing data, separately. This way, we can isolate which firms and/or time periods contain complete or incomplete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast has 82 time periods containing missing data, out of 84 total rows.\n",
      "eps_actual has 84 time periods containing missing data, out of 84 total rows.\n",
      "eod_actual has 83 time periods containing missing data, out of 84 total rows.\n",
      "eps_fcast_terms has 80 time periods containing missing data, out of 80 total rows.\n"
     ]
    }
   ],
   "source": [
    "#check rows for missing data\n",
    "for key, df in dict_dfs.items():\n",
    "    num_rows_missing = df.isna().sum().max()\n",
    "    print('{} has {} time periods containing missing data, out of {} total rows.'.format(key, num_rows_missing, df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(eps_fc.columns[eps_fc.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast has 254 firms containing missing data, out of 506 total columns.\n",
      "eps_actual has 432 firms containing missing data, out of 507 total columns.\n",
      "eod_actual has 505 firms containing missing data, out of 506 total columns.\n",
      "eps_fcast_terms has 340 firms containing missing data, out of 507 total columns.\n"
     ]
    }
   ],
   "source": [
    "#check columns for missing data\n",
    "for key, df in dict_dfs.items():\n",
    "    cols_missing = df.columns[df.isnull().any()]\n",
    "    num_cols_missing = len(cols_missing)\n",
    "    print('{} has {} firms containing missing data, out of {} total columns.'\n",
    "         .format(key, num_cols_missing, df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation 1:** The only two datasets with incomplete data for all time periods are **actual EPS** and **forecasted EPS 3 months prior.**\n",
    "\n",
    "> To address this problem, it'd be helpful to isolate the time period ranges for the datasets with incomplete data by row, **forecasted EPS** and **actual EOD price.**\n",
    "\n",
    "**Observation 2:** For all datasets, all firms contain incomplete data across all time periods.\n",
    "> This is expected, as analyzing financial history spanning over 20 years will naturally be rife with missing and inaccurate data. The ***good news is that `eps_fcast`, `eps_actual`, and `eps_fcast_terms` are the most complete, while `eod_actual` contains the most amount of missing data.***\n",
    "\n",
    "\n",
    "**Moving forward, we need to make sure that these inconsistencies won't clash with our analysis.**\n",
    "> **My approach:** instead of looking at rows and columns ***with*** missing data, we'll be looking at rows and columns that ***are all missing data.***\n",
    "\n",
    "I figured that if there is some missing data here and there scattered throughout the matrix, then that should not skew our analysis too much.\n",
    "\n",
    "However, if there a significant amount of rows/columns that are entirely empty, then we ***might have to get ready to drop some dates and firms from our data overall.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast \n",
      " False    84\n",
      "dtype: int64 \n",
      "----\n",
      "eps_actual \n",
      " False    84\n",
      "dtype: int64 \n",
      "----\n",
      "eod_actual \n",
      " False    84\n",
      "dtype: int64 \n",
      "----\n",
      "eps_fcast_terms \n",
      " False    80\n",
      "dtype: int64 \n",
      "----\n"
     ]
    }
   ],
   "source": [
    "#check for empty rows, return False if row contains at least one non-null value, True if all are null\n",
    "for key, df in dict_dfs.items():\n",
    "    cols_check = df.columns\n",
    "    num_empty_rows = (df[cols_check].isnull().apply(lambda x: all(x), axis = 1)).value_counts()\n",
    "    print(key, '\\n', num_empty_rows, '\\n----')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** All datasets do not contain empty rows.\n",
    "> This is good news, since we can rely on the firms' averages per row instead of having to drop or limit time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast \n",
      " False    506\n",
      "dtype: int64\n",
      "eps_actual \n",
      " False    506\n",
      "True       1\n",
      "dtype: int64\n",
      "eod_actual \n",
      " False    506\n",
      "dtype: int64\n",
      "eps_fcast_terms \n",
      " False    506\n",
      "True       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for empty columns, return False if column contains at least one non-null value, True if all are null\n",
    "for key, df in dict_dfs.items():\n",
    "    cols_check = df.columns\n",
    "    num_empty_cols = df[cols_check].isnull().apply(lambda x: all(x), axis = 0).value_counts()\n",
    "    print(key, '\\n', num_empty_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** `eps_actual` and `eps_fcast_terms` are the only datasets that have an empty column.\n",
    "> Let's isolate and look at the singular empty column for both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to return an array of column names containing empty data\n",
    "def comb_cols(df):\n",
    "    empty_cols = []\n",
    "    for column in df:\n",
    "        if df[column].isnull().all():\n",
    "            empty_cols.append(column)\n",
    "            \n",
    "    return empty_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In eps_act, the firm ['AMCR UN Equity'] has no data.\n",
      "In eps_fc_terms, the firm ['AMCR UN Equity'] has no data.\n"
     ]
    }
   ],
   "source": [
    "#comb datasets for empty columns\n",
    "print('In eps_act, the firm {} has no data.'.format(comb_cols(eps_act)))\n",
    "print('In eps_fc_terms, the firm {} has no data.'.format(comb_cols(eps_fc_terms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The same firm in both datasets is empty of data.\n",
    "> Though this is an annoying error to deal with, it still is to our advantage that both datasets ***share one firm*** in common for missing data. This way, we don't have to worry about dropping two entire firms.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check Duplicate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast 0\n",
      "eps_actual 0\n",
      "eod_actual 0\n",
      "eps_fcast_terms 0\n"
     ]
    }
   ],
   "source": [
    "#check for duplicate data across all rows and columns\n",
    "for key, df in dict_dfs.items():\n",
    "    print(key, df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** For all datasets, there are ***no duplicate data.*** This is good news!\n",
    "\n",
    "**Next, I will check for duplicated firm names.** Although the presence of duplicated firm names will inherently imply duplicated data, sometimes data gets dispersed in weird, unexpected ways, especially when dealing with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast 0\n",
      "eps_actual 0\n",
      "eod_actual 0\n",
      "eps_fcast_terms 0\n"
     ]
    }
   ],
   "source": [
    "#check for duplicated firm names\n",
    "for key, df in dict_dfs.items():\n",
    "    print(key, df.columns.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** For all datasets, there are ***no duplicate firm names.*** This is also good news.\n",
    "\n",
    "### There is no need to dedupe our data during the cleaning stage.\n",
    "\n",
    "---\n",
    "\n",
    "### Check Data Types\n",
    "\n",
    "> Make sure all numerical data types are consistent.\n",
    "- EPS and EOD values must all be **floats**\n",
    "- Dates should all be **objects** (for now)\n",
    "\n",
    "- `eps_fc` contains ***1 date field,***, so we should expect ***1 object type.***\n",
    "- `eps_act` contains ***2 date fields,*** so we should expect ***2 object types.***\n",
    "- `eod_act` contains ***1 date field,*** so we should expect ***1 object type.***\n",
    "- `eps_fc_terms` contains ***2 date fields,*** so we should expect ***2 object types.***\n",
    "\n",
    "> And everything else should be a ***float*** type.\n",
    "\n",
    "**Examine each dataset's overall data types per column.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast \n",
      " float64    505\n",
      "object       1\n",
      "dtype: int64 \n",
      "--------\n",
      "eps_actual \n",
      " float64    499\n",
      "object       7\n",
      "int64        1\n",
      "dtype: int64 \n",
      "--------\n",
      "eod_actual \n",
      " float64    505\n",
      "object       1\n",
      "dtype: int64 \n",
      "--------\n",
      "eps_fcast_terms \n",
      " float64    505\n",
      "object       2\n",
      "dtype: int64 \n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "for key, df in dict_dfs.items():\n",
    "    print(key,'\\n', df.dtypes.value_counts(), '\\n--------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation 1:** `eps_fc`, `eod_act`, and `eps_fc_terms` are all consistent with the expected number of object types.\n",
    "\n",
    "> But we'll still have to double check these facts later.\n",
    "\n",
    "**Observation 2:** `eps_act` contains 5 more object columns than expected.\n",
    "\n",
    "---\n",
    "\n",
    "***Isolate 'Object' Columns under `eps_act`***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>BRK/B UN Equity</th>\n",
       "      <th>FOX UW Equity</th>\n",
       "      <th>GOOG UW Equity</th>\n",
       "      <th>HCP UN Equity</th>\n",
       "      <th>SYMC UW Equity</th>\n",
       "      <th>UA UN Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "      <td>#N/A Field Not Applicable</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quarter            BRK/B UN Equity              FOX UW Equity  \\\n",
       "0      Q1  #N/A Field Not Applicable  #N/A Field Not Applicable   \n",
       "1      Q2  #N/A Field Not Applicable  #N/A Field Not Applicable   \n",
       "2      Q3  #N/A Field Not Applicable  #N/A Field Not Applicable   \n",
       "3      Q4  #N/A Field Not Applicable  #N/A Field Not Applicable   \n",
       "4      Q1  #N/A Field Not Applicable  #N/A Field Not Applicable   \n",
       "\n",
       "              GOOG UW Equity              HCP UN Equity  \\\n",
       "0  #N/A Field Not Applicable  #N/A Field Not Applicable   \n",
       "1  #N/A Field Not Applicable  #N/A Field Not Applicable   \n",
       "2  #N/A Field Not Applicable  #N/A Field Not Applicable   \n",
       "3  #N/A Field Not Applicable  #N/A Field Not Applicable   \n",
       "4  #N/A Field Not Applicable  #N/A Field Not Applicable   \n",
       "\n",
       "              SYMC UW Equity               UA UN Equity  \n",
       "0  #N/A Field Not Applicable  #N/A Field Not Applicable  \n",
       "1  #N/A Field Not Applicable  #N/A Field Not Applicable  \n",
       "2  #N/A Field Not Applicable  #N/A Field Not Applicable  \n",
       "3  #N/A Field Not Applicable  #N/A Field Not Applicable  \n",
       "4  #N/A Field Not Applicable  #N/A Field Not Applicable  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_act.select_dtypes(include = 'object').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** These firms are all 'Object' types because there is no recorded data under them.\n",
    "> This is actually missing data. From `eps_act`, there are 6 firms that are empty of data.\n",
    "\n",
    "### This was a tricky situation to spot, but I caught it in the end. There actually is missing data after all, but we missed those 5 entire firms during the \"Check Missing Data\" stage, because they were recorded as objects. This means that Pandas wrongly recognized these 5 firms as \"complete.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quality\n",
    "\n",
    "**Missing Data**\n",
    "> **In the end, I decided not to drop any rows or columns with missing data. For the sake of data preservation, I kept all missing data recorded as NaN.**\n",
    "\n",
    "-  `eps_fc_terms` is missing the year 1999.\n",
    "- `eps_act` and `eps_fc_act` have one firm with empty data: 'AMCR UN Equity'\n",
    "- `eps_act` contains 7 empty firms: BRK/B UN Equity, FOX UW Equity, GOOG UW Equity, HCP UN Equity, SYMC UW Equity, UA UN Equity\n",
    "--- \n",
    "- Unnormalized date formats among all DataFrames.\n",
    "- Firm names across all DataFrames are capitalized and contain white space.\n",
    "- Erroneous data type for `eps_act` Object columns.\n",
    "- Erroneous data type for **date** under `eod_act`\n",
    "- Erroneous data type for **forecast_made** under `eps_fc_terms`\n",
    "- Erroneous data types for **term_forecast** under `eps_act`, `eps_fc`, and `eps_fc_terms` to DateTime quarter index\n",
    "- No recorded quarterly data for `eod_act`\n",
    "---\n",
    "- Firm names not referenced by **firm_id**\n",
    "- No recorded 20-year for each dataset.\n",
    "- No recorded yearly averages for each dataset\n",
    "- No recorded quarterly averages for each dataset.\n",
    "---\n",
    "- Features datasets \n",
    "\n",
    "### Tidiness\n",
    "- Unnormalized data among `df_twenty_year_avgs`, `df_yearly_avgs`, and `df_quarter_avgs`\n",
    "- 20-year, yearly, and quarterly averages contained in different DataFrames.\n",
    "- Unnormalized data among `eps_act`, `eps_fc`, `eod_act`, and `eps_fc_terms`\n",
    "\n",
    "\n",
    "### C) CLEAN <a id=\"clean\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_fc_clean = eps_fc.copy()\n",
    "eps_act_clean = eps_act.copy()\n",
    "eod_act_clean = eod_act.copy()\n",
    "eps_fc_terms_clean = eps_fc_terms.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create dictionary of all clean dfs for iteration\n",
    "dict_clean = {'eps_fc_clean' : eps_fc_clean,\n",
    "             'eps_act_clean' : eps_act_clean,\n",
    "             'eod_act_clean' : eod_act_clean,\n",
    "             'eps_fc_terms_clean' : eps_fc_terms_clean}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "> **ISSUE 1:**  Unnormalized date formats among all DataFrames.\n",
    "\n",
    "**Define:** \n",
    "- Conjoin `eps_act_clean` dates from 2 columns into 1 to match `eps_fc_clean` format.\n",
    "> The format we want is YYYYQN. For example, Quarter 1 in 2005 will be 2005Q1.\n",
    "\n",
    "- Rename both fiscal periods under `eps_act_clean` and `eps_fc_clean` to **term_forecast.**\n",
    "\n",
    "- For both fiscal periods under `eps_fc_terms_clean`, add an underscore.\n",
    "- Under `eps_fc_terms_clean`, format **term_forecasted** to YYYYQN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column, combine year and quarter into 1 string\n",
    "eps_act_clean['term_forecast'] = eps_act_clean['Year'].map(str) + eps_act_clean['Quarter']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop 'Year' and 'Quarter'\n",
    "eps_act_clean.drop(['Year', 'Quarter'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#designate new column as first column\n",
    "reorder_cols = eps_act_clean.columns.tolist()\n",
    "reorder_cols.insert(0, reorder_cols.pop(reorder_cols.index('term_forecast')))\n",
    "\n",
    "eps_act_clean = eps_act_clean.reindex(columns = reorder_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename eps_fc_clean fiscal period to term_forecast\n",
    "eps_fc_clean.rename(index = str, columns = {'Term Forecasted' : 'term_forecast'}, inplace = True)\n",
    "\n",
    "#reassign to dictionary\n",
    "dict_clean['eps_act_clean'] = eps_act_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:5096: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    }
   ],
   "source": [
    "eps_fc_clean[4:].term_forecast = '20' + eps_fc_clean[4:].term_forecast.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add an underscore for both date periods under eps_fc_terms_clean\n",
    "eps_fc_terms_clean.rename(index = str, columns = {'Forecast Made' : 'forecast_made',\n",
    "                                                 'Term Forecasted' : 'term_forecast'},\n",
    "                         inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#under term_forecaste, add a '20' before each string\n",
    "eps_fc_terms_clean.term_forecast = '20' + eps_fc_terms_clean.term_forecast.astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_forecast</th>\n",
       "      <th>A UN Equity</th>\n",
       "      <th>AAL UW Equity</th>\n",
       "      <th>AAP UN Equity</th>\n",
       "      <th>AAPL UW Equity</th>\n",
       "      <th>ABBV UN Equity</th>\n",
       "      <th>ABC UN Equity</th>\n",
       "      <th>ABMD UW Equity</th>\n",
       "      <th>ABT UN Equity</th>\n",
       "      <th>ACN UN Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL UW Equity</th>\n",
       "      <th>XLNX UW Equity</th>\n",
       "      <th>XOM UN Equity</th>\n",
       "      <th>XRAY UW Equity</th>\n",
       "      <th>XRX UN Equity</th>\n",
       "      <th>XYL UN Equity</th>\n",
       "      <th>YUM UN Equity</th>\n",
       "      <th>ZBH UN Equity</th>\n",
       "      <th>ZION UW Equity</th>\n",
       "      <th>ZTS UN Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>2017Q2</td>\n",
       "      <td>0.484</td>\n",
       "      <td>1.872</td>\n",
       "      <td>1.659</td>\n",
       "      <td>2.022</td>\n",
       "      <td>1.399</td>\n",
       "      <td>1.679</td>\n",
       "      <td>0.244</td>\n",
       "      <td>0.605</td>\n",
       "      <td>1.299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.419</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.798</td>\n",
       "      <td>0.569</td>\n",
       "      <td>0.619</td>\n",
       "      <td>2.085</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>2016Q2</td>\n",
       "      <td>0.389</td>\n",
       "      <td>1.678</td>\n",
       "      <td>2.111</td>\n",
       "      <td>1.998</td>\n",
       "      <td>1.200</td>\n",
       "      <td>1.585</td>\n",
       "      <td>0.155</td>\n",
       "      <td>0.533</td>\n",
       "      <td>1.184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.637</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.474</td>\n",
       "      <td>0.739</td>\n",
       "      <td>1.968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>2012Q2</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.217</td>\n",
       "      <td>1.389</td>\n",
       "      <td>1.438</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.811</td>\n",
       "      <td>-0.091</td>\n",
       "      <td>1.217</td>\n",
       "      <td>0.860</td>\n",
       "      <td>...</td>\n",
       "      <td>0.355</td>\n",
       "      <td>0.437</td>\n",
       "      <td>1.953</td>\n",
       "      <td>0.557</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.489</td>\n",
       "      <td>0.704</td>\n",
       "      <td>1.317</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 506 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   term_forecast  A UN Equity  AAL UW Equity  AAP UN Equity  AAPL UW Equity  \\\n",
       "73        2017Q2        0.484          1.872          1.659           2.022   \n",
       "69        2016Q2        0.389          1.678          2.111           1.998   \n",
       "53        2012Q2        0.731          0.217          1.389           1.438   \n",
       "\n",
       "    ABBV UN Equity  ABC UN Equity  ABMD UW Equity  ABT UN Equity  \\\n",
       "73           1.399          1.679           0.244          0.605   \n",
       "69           1.200          1.585           0.155          0.533   \n",
       "53             NaN          0.811          -0.091          1.217   \n",
       "\n",
       "    ACN UN Equity  ...  XEL UW Equity  XLNX UW Equity  XOM UN Equity  \\\n",
       "73          1.299  ...          0.419           0.546          0.843   \n",
       "69          1.184  ...          0.404           0.469          0.637   \n",
       "53          0.860  ...          0.355           0.437          1.953   \n",
       "\n",
       "    XRAY UW Equity  XRX UN Equity  XYL UN Equity  YUM UN Equity  \\\n",
       "73           0.652          0.798          0.569          0.619   \n",
       "69           0.700          0.981          0.474          0.739   \n",
       "53           0.557            NaN          0.489          0.704   \n",
       "\n",
       "    ZBH UN Equity  ZION UW Equity  ZTS UN Equity  \n",
       "73          2.085            0.62          0.527  \n",
       "69          1.968             NaN          0.444  \n",
       "53          1.317             NaN            NaN  \n",
       "\n",
       "[3 rows x 506 columns]"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#give overview of both DataFrames\n",
    "eps_fc_clean.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term_forecast</th>\n",
       "      <th>A UN Equity</th>\n",
       "      <th>AAL UW Equity</th>\n",
       "      <th>AAP UN Equity</th>\n",
       "      <th>AAPL UW Equity</th>\n",
       "      <th>ABBV UN Equity</th>\n",
       "      <th>ABC UN Equity</th>\n",
       "      <th>ABMD UW Equity</th>\n",
       "      <th>ABT UN Equity</th>\n",
       "      <th>ACN UN Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL UW Equity</th>\n",
       "      <th>XLNX UW Equity</th>\n",
       "      <th>XOM UN Equity</th>\n",
       "      <th>XRAY UW Equity</th>\n",
       "      <th>XRX UN Equity</th>\n",
       "      <th>XYL UN Equity</th>\n",
       "      <th>YUM UN Equity</th>\n",
       "      <th>ZBH UN Equity</th>\n",
       "      <th>ZION UW Equity</th>\n",
       "      <th>ZTS UN Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>2012Q4</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.785075</td>\n",
       "      <td>0.890000</td>\n",
       "      <td>1.251429</td>\n",
       "      <td>0.976538</td>\n",
       "      <td>0.670</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.910000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.46</td>\n",
       "      <td>2.20</td>\n",
       "      <td>0.89</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.392262</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.19</td>\n",
       "      <td>-0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2008Q1</td>\n",
       "      <td>0.32</td>\n",
       "      <td>-1.370000</td>\n",
       "      <td>0.860000</td>\n",
       "      <td>0.258571</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.335</td>\n",
       "      <td>-0.26</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.597063</td>\n",
       "      <td>...</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.45</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.522634</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.98</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2002Q3</td>\n",
       "      <td>-0.49</td>\n",
       "      <td>-5.920000</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.006429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.215</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>...</td>\n",
       "      <td>-5.22</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.245000</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.43</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 506 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   term_forecast  A UN Equity  AAL UW Equity  AAP UN Equity  AAPL UW Equity  \\\n",
       "55        2012Q4         1.22       0.785075       0.890000        1.251429   \n",
       "36        2008Q1         0.32      -1.370000       0.860000        0.258571   \n",
       "14        2002Q3        -0.49      -5.920000       0.266667        0.006429   \n",
       "\n",
       "    ABBV UN Equity  ABC UN Equity  ABMD UW Equity  ABT UN Equity  \\\n",
       "55        0.976538          0.670            0.07           0.66   \n",
       "36             NaN          0.335           -0.26           0.61   \n",
       "14             NaN          0.215           -0.25           0.46   \n",
       "\n",
       "    ACN UN Equity  ...  XEL UW Equity  XLNX UW Equity  XOM UN Equity  \\\n",
       "55       0.910000  ...           0.29            0.46           2.20   \n",
       "36       0.597063  ...           0.35            0.28           2.05   \n",
       "14       0.280000  ...          -5.22            0.03           0.39   \n",
       "\n",
       "    XRAY UW Equity  XRX UN Equity  XYL UN Equity  YUM UN Equity  \\\n",
       "55            0.89           1.04       0.392262       0.740000   \n",
       "36            0.45          -1.08            NaN       0.522634   \n",
       "14            0.23           0.20            NaN       0.245000   \n",
       "\n",
       "    ZBH UN Equity  ZION UW Equity  ZTS UN Equity  \n",
       "55           0.88            0.19          -0.02  \n",
       "36           1.03            0.98            NaN  \n",
       "14           0.33            0.43            NaN  \n",
       "\n",
       "[3 rows x 506 columns]"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_act_clean.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True    84\n",
       "Name: term_forecast, dtype: int64"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check consistent format between both `term_forecast` fields\n",
    "forecasts = pd.concat([eps_fc_clean.term_forecast, eps_act_clean.term_forecast])\n",
    "\n",
    "#count number of instances where unique term_forecast values are the same\n",
    "(forecasts.value_counts().sort_index() == 2).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['term_forecast', 'A UN Equity'], dtype='object')\n",
      "Index(['term_forecast', 'A UN Equity'], dtype='object')\n",
      "Index(['date', 'A UN Equity'], dtype='object')\n",
      "Index(['forecast_made', 'term_forecast'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#check that dates are the first columns\n",
    "for key, df in dict_clean.items():\n",
    "    print(df.columns[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The **term_forecast** fields under `eps_fc_clean`, `eps_act_clean`, and `eps_fc_terms_clean` are all normalized to YYYQN format. This means `eod_act_clean` is the only one with a different date formatting rule.\n",
    "\n",
    "### Code\n",
    "> **ISSUE 2:** Firm names across all DataFrames are capitalized and contain white space.\n",
    "\n",
    "**Define:** Iterate across all DataFrames. Get rid of everything from the first whitespace character onward. Lowercase column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lowercase names\n",
    "for key, df in dict_clean.items():\n",
    "    lower_cols = [x.lower() for x in df.columns]\n",
    "    df.columns = lower_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get rid of white space\n",
    "for key, df in dict_clean.items():\n",
    "    stock_symbols = [x.split(' ', 1)[0] for x in df.columns]\n",
    "    df.columns = stock_symbols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that all firm names are consistent, should return 505 firm results\n",
    "all_ticks = []\n",
    "for key, df in dict_clean.items():\n",
    "    firm_ticks = np.array(df.columns.values)\n",
    "    all_ticks.append(firm_ticks)\n",
    "    \n",
    "#flatten array\n",
    "all_ticks = np.hstack(all_ticks)\n",
    "\n",
    "#assign tick names to Pandas Series\n",
    "all_ticks = pd.Series(all_ticks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date             1\n",
       "forecast_made    1\n",
       "term_forecast    3\n",
       "xec              4\n",
       "mro              4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 327,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at lowest 3 value counts, SHOULD BE DATE PERIODS\n",
    "all_ticks.value_counts().sort_values()[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "jci     4\n",
       "alxn    4\n",
       "dte     4\n",
       "cci     4\n",
       "holx    4\n",
       "dtype: int64"
      ]
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#look at highest value counts, should be FOUR (because there are 4 dataframes all with firm names)\n",
    "all_ticks.value_counts().sort_values(ascending = False)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 329,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for any upper case instance among columns\n",
    "all_ticks.str.isupper().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for any white space\n",
    "all_ticks.str.contains(' ').any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "> **ISSUE 3:** Erroneous data type for `eps_act` Object columns.\n",
    "\n",
    "**Define:**\n",
    "\n",
    "- Convert '#N/A Field Not Applicable' strings into 'NaN'\n",
    "- Convert the 6 `eps_act_clean` Object columns into NaN type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate 6 firm names recorded as 'object'\n",
    "obj_ticks = eps_act_clean.select_dtypes(include = 'object').columns.values\n",
    "\n",
    "#exclude 'term_forecast'\n",
    "obj_ticks = obj_ticks[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to NaN\n",
    "str_replace = '#N/A Field Not Applicable'\n",
    "eps_act_clean[obj_ticks] = eps_act_clean[obj_ticks].replace(str_replace, np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Columns: 506 entries, term_forecast to zts\n",
      "dtypes: float64(505), object(1)\n",
      "memory usage: 332.1+ KB\n"
     ]
    }
   ],
   "source": [
    "eps_act_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['term_forecast']"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make sure 'term_forecast' is the only object-type column\n",
    "eps_act_clean.select_dtypes(include = 'object').columns.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "\n",
    "> **ISSUE 4:**  Erroneous data type for **date** under `eod_act`\n",
    "\n",
    "**Define:** Convert column `date` to DateTime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "eod_act_clean.date = pd.to_datetime(eod_act_clean.date, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>a</th>\n",
       "      <th>aal</th>\n",
       "      <th>aap</th>\n",
       "      <th>aapl</th>\n",
       "      <th>abbv</th>\n",
       "      <th>abc</th>\n",
       "      <th>abmd</th>\n",
       "      <th>abt</th>\n",
       "      <th>acn</th>\n",
       "      <th>...</th>\n",
       "      <th>xel</th>\n",
       "      <th>xlnx</th>\n",
       "      <th>xom</th>\n",
       "      <th>xray</th>\n",
       "      <th>xrx</th>\n",
       "      <th>xyl</th>\n",
       "      <th>yum</th>\n",
       "      <th>zbh</th>\n",
       "      <th>zion</th>\n",
       "      <th>zts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2008-12-31</td>\n",
       "      <td>11.1768</td>\n",
       "      <td>NaN</td>\n",
       "      <td>33.65</td>\n",
       "      <td>12.1929</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.8300</td>\n",
       "      <td>16.420</td>\n",
       "      <td>25.5361</td>\n",
       "      <td>32.79</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.8200</td>\n",
       "      <td>79.83</td>\n",
       "      <td>28.2400</td>\n",
       "      <td>20.9977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.6502</td>\n",
       "      <td>40.42</td>\n",
       "      <td>24.5100</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2000-06-30</td>\n",
       "      <td>49.6906</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.7411</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.5201</td>\n",
       "      <td>15.375</td>\n",
       "      <td>19.9435</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.5625</td>\n",
       "      <td>39.25</td>\n",
       "      <td>10.2708</td>\n",
       "      <td>54.6678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0783</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.8906</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 506 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date        a  aal    aap     aapl  abbv      abc    abmd      abt  \\\n",
       "39 2008-12-31  11.1768  NaN  33.65  12.1929   NaN  17.8300  16.420  25.5361   \n",
       "5  2000-06-30  49.6906  NaN    NaN   3.7411   NaN   7.5201  15.375  19.9435   \n",
       "\n",
       "      acn  ...  xel     xlnx    xom     xray      xrx  xyl      yum    zbh  \\\n",
       "39  32.79  ...  NaN  17.8200  79.83  28.2400  20.9977  NaN  22.6502  40.42   \n",
       "5     NaN  ...  NaN  82.5625  39.25  10.2708  54.6678  NaN   5.0783    NaN   \n",
       "\n",
       "       zion  zts  \n",
       "39  24.5100  NaN  \n",
       "5   45.8906  NaN  \n",
       "\n",
       "[2 rows x 506 columns]"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eod_act_clean.sample(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Columns: 506 entries, date to zts\n",
      "dtypes: datetime64[ns](1), float64(505)\n",
      "memory usage: 332.1 KB\n"
     ]
    }
   ],
   "source": [
    "#confirm datetime64 present\n",
    "eod_act_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "> **ISSUE 5:** Erroneous data type for **forecast_made** under `eps_fc_terms`.\n",
    "\n",
    "**Define:**\n",
    "\n",
    "- Convert column **forecast_made** to DateTime object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_fc_terms_clean.forecast_made = pd.to_datetime(eps_fc_terms_clean.forecast_made, infer_datetime_format=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 80 entries, 0 to 79\n",
      "Columns: 507 entries, forecast_made to zts\n",
      "dtypes: datetime64[ns](1), float64(505), object(1)\n",
      "memory usage: 317.5+ KB\n"
     ]
    }
   ],
   "source": [
    "#confirm presence of datetime64 object\n",
    "eps_fc_terms_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>forecast_made</th>\n",
       "      <th>term_forecast</th>\n",
       "      <th>a</th>\n",
       "      <th>aal</th>\n",
       "      <th>aap</th>\n",
       "      <th>aapl</th>\n",
       "      <th>abbv</th>\n",
       "      <th>abc</th>\n",
       "      <th>abmd</th>\n",
       "      <th>abt</th>\n",
       "      <th>...</th>\n",
       "      <th>xel</th>\n",
       "      <th>xlnx</th>\n",
       "      <th>xom</th>\n",
       "      <th>xray</th>\n",
       "      <th>xrx</th>\n",
       "      <th>xyl</th>\n",
       "      <th>yum</th>\n",
       "      <th>zbh</th>\n",
       "      <th>zion</th>\n",
       "      <th>zts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2005-01-01</td>\n",
       "      <td>2005Q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.022</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0.240</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.306</td>\n",
       "      <td>0.705</td>\n",
       "      <td>1.210</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2002-10-01</td>\n",
       "      <td>2003Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.233</td>\n",
       "      <td>0.007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>0.585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.225</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.217</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   forecast_made term_forecast   a  aal    aap   aapl  abbv  abc  abmd    abt  \\\n",
       "21    2005-01-01        2005Q2 NaN  NaN  0.536  0.022   NaN  NaN -0.03  0.600   \n",
       "12    2002-10-01        2003Q1 NaN  NaN  0.233  0.007   NaN  NaN -0.34  0.585   \n",
       "\n",
       "    ...    xel   xlnx   xom   xray  xrx  xyl    yum    zbh   zion  zts  \n",
       "21  ...  0.203  0.240  0.88  0.330  NaN  NaN  0.306  0.705  1.210  NaN  \n",
       "12  ...  0.280  0.116  0.52  0.225  NaN  NaN  0.217  0.333  0.965  NaN  \n",
       "\n",
       "[2 rows x 507 columns]"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eps_fc_terms_clean.sample(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "> **ISSUE 6:** Erroneous data types for **term_forecast** under `eps_act`, `eps_fc`, and `eps_fc_terms` to DateTime quarter index\n",
    "\n",
    "**Define:** Convert YYYYQQ formats into DateTime quarter index type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to turn a column into Quarter Period type\n",
    "def convert_period(df, col):\n",
    "    return pd.to_datetime(df[col]).dt.to_period('Q')\n",
    "# eps_fc_terms_clean.term_forecast = pd.PeriodIndex(eps_fc_terms_clean.term_forecast, freq='Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert term_forecast fields to Period type\n",
    "eps_fc_clean.term_forecast = convert_period(eps_fc_clean, 'term_forecast')\n",
    "eps_act_clean.term_forecast = convert_period(eps_act_clean, 'term_forecast')\n",
    "eps_fc_terms_clean.term_forecast = convert_period(eps_fc_terms_clean, 'term_forecast')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "period[Q-DEC]\n",
      "period[Q-DEC]\n",
      "period[Q-DEC]\n"
     ]
    }
   ],
   "source": [
    "#verify Period Object types\n",
    "print(eps_fc_clean.dtypes['term_forecast'])\n",
    "print(eps_act_clean.dtypes['term_forecast'])\n",
    "print(eps_fc_terms_clean.dtypes['term_forecast'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "> **ISSUE 7:** No recorded quarterly data for `eod_act`\n",
    "\n",
    "**Define:** Add a new column **term_forecast** denoting *year* and *quarter*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "eod_act_clean['term_forecast'] = eod_act_clean.date.dt.to_period('Q')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder columns\n",
    "eod_cols = ['date', 'term_forecast'] + [col for col in eod_act_clean.iloc[:, 1:] if col!='term_forecast']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "eod_act_clean = eod_act_clean.reindex(columns = eod_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>term_forecast</th>\n",
       "      <th>a</th>\n",
       "      <th>aal</th>\n",
       "      <th>aap</th>\n",
       "      <th>aapl</th>\n",
       "      <th>abbv</th>\n",
       "      <th>abc</th>\n",
       "      <th>abmd</th>\n",
       "      <th>abt</th>\n",
       "      <th>...</th>\n",
       "      <th>xel</th>\n",
       "      <th>xlnx</th>\n",
       "      <th>xom</th>\n",
       "      <th>xray</th>\n",
       "      <th>xrx</th>\n",
       "      <th>xyl</th>\n",
       "      <th>yum</th>\n",
       "      <th>zbh</th>\n",
       "      <th>zion</th>\n",
       "      <th>zts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999-03-31</td>\n",
       "      <td>1999Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.2934</td>\n",
       "      <td>6.250</td>\n",
       "      <td>20.9504</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.2813</td>\n",
       "      <td>35.2813</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>140.6214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.6284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.5000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999-06-30</td>\n",
       "      <td>1999Q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1859</td>\n",
       "      <td>6.875</td>\n",
       "      <td>20.3630</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.6250</td>\n",
       "      <td>38.5625</td>\n",
       "      <td>9.6250</td>\n",
       "      <td>155.6057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.7297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.5000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999-09-30</td>\n",
       "      <td>1999Q3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7462</td>\n",
       "      <td>7.750</td>\n",
       "      <td>16.4471</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.7656</td>\n",
       "      <td>37.9688</td>\n",
       "      <td>7.5833</td>\n",
       "      <td>110.4883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.3591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.1250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999-12-31</td>\n",
       "      <td>1999Q4</td>\n",
       "      <td>52.0909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6843</td>\n",
       "      <td>18.375</td>\n",
       "      <td>16.2513</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.4688</td>\n",
       "      <td>40.2813</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>59.7723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.9434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.1875</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2000-03-31</td>\n",
       "      <td>2000Q1</td>\n",
       "      <td>70.0721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6388</td>\n",
       "      <td>20.250</td>\n",
       "      <td>15.7478</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.8125</td>\n",
       "      <td>38.9063</td>\n",
       "      <td>9.4583</td>\n",
       "      <td>68.4994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        date term_forecast        a  aal  aap    aapl  abbv     abc    abmd  \\\n",
       "0 1999-03-31        1999Q1      NaN  NaN  NaN  1.2835   NaN  8.2934   6.250   \n",
       "1 1999-06-30        1999Q2      NaN  NaN  NaN  1.6540   NaN  6.1859   6.875   \n",
       "2 1999-09-30        1999Q3      NaN  NaN  NaN  2.2612   NaN  5.7462   7.750   \n",
       "3 1999-12-31        1999Q4  52.0909  NaN  NaN  3.6719   NaN  3.6843  18.375   \n",
       "4 2000-03-31        2000Q1  70.0721  NaN  NaN  4.8504   NaN  3.6388  20.250   \n",
       "\n",
       "       abt  ...  xel     xlnx      xom    xray       xrx  xyl      yum  zbh  \\\n",
       "0  20.9504  ...  NaN  20.2813  35.2813  7.7500  140.6214  NaN  12.6284  NaN   \n",
       "1  20.3630  ...  NaN  28.6250  38.5625  9.6250  155.6057  NaN   9.7297  NaN   \n",
       "2  16.4471  ...  NaN  32.7656  37.9688  7.5833  110.4883  NaN   7.3591  NaN   \n",
       "3  16.2513  ...  NaN  45.4688  40.2813  7.8750   59.7723  NaN   6.9434  NaN   \n",
       "4  15.7478  ...  NaN  82.8125  38.9063  9.4583   68.4994  NaN   5.5839  NaN   \n",
       "\n",
       "      zion  zts  \n",
       "0  66.5000  NaN  \n",
       "1  63.5000  NaN  \n",
       "2  55.1250  NaN  \n",
       "3  59.1875  NaN  \n",
       "4  41.6250  NaN  \n",
       "\n",
       "[5 rows x 507 columns]"
      ]
     },
     "execution_count": 347,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify column order\n",
    "eod_act_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify 84 columns\n",
    "eod_act_clean.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 84 entries, 0 to 83\n",
      "Columns: 507 entries, date to zts\n",
      "dtypes: datetime64[ns](1), float64(505), period[Q-DEC](1)\n",
      "memory usage: 332.8 KB\n"
     ]
    }
   ],
   "source": [
    "eod_act_clean.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All full years are normalized to YYYY-MM-DD, and all quarterly records to YYYY-QQ.\n",
    "\n",
    "## This is to enable for more efficient handling, cleaning, and classifying of data later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "\n",
    "**ISSUE 7:** Firm names not referenced by **firm_id**\n",
    "\n",
    "**Define:**\n",
    "- Assign a **firm_id** to each firm for future normalization.\n",
    "\n",
    "- Generate new CSV named `firms.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get firm names\n",
    "firm_names = eps_act_clean.columns[1:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign ids to firm names\n",
    "firm_names_ids = {}\n",
    "counter = 0\n",
    "\n",
    "for firm in firm_names:\n",
    "    firm_names_ids.update({firm: counter})\n",
    "    counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate new DF\n",
    "firm_ids = pd.DataFrame(list(firm_names_ids.items())).rename(columns = {0: 'firm', 1: 'firm_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#switch firm and firm_id columns\n",
    "firm_ids = firm_ids.reindex(columns = ['firm_id', 'firm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>firm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>501</td>\n",
       "      <td>yum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>140</td>\n",
       "      <td>dis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>72</td>\n",
       "      <td>bll</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>427</td>\n",
       "      <td>swks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>expe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>abbv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>301</td>\n",
       "      <td>ma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>86</td>\n",
       "      <td>cbs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>abc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>453</td>\n",
       "      <td>uaa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     firm_id  firm\n",
       "501      501   yum\n",
       "140      140   dis\n",
       "72        72   bll\n",
       "427      427  swks\n",
       "176      176  expe\n",
       "4          4  abbv\n",
       "301      301    ma\n",
       "86        86   cbs\n",
       "5          5   abc\n",
       "453      453   uaa"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "firm_ids.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 505 entries, 0 to 504\n",
      "Data columns (total 2 columns):\n",
      "firm_id    505 non-null int64\n",
      "firm       505 non-null object\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 8.0+ KB\n"
     ]
    }
   ],
   "source": [
    "firm_ids.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "> **ISSUE 7:** No recorded 20-year averages for each dataset.\n",
    "\n",
    "**Define:**\n",
    "\n",
    "\n",
    "- Isolate 20-year averages for each firm into its own DataFrame\n",
    "\n",
    "- Create new DataFrame `twenty_avgs` depicting all 20-year averages for each firm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert foreign keys to str temporarily\n",
    "firm_ids_str = {str(k):str(v) for k, v in firm_names_ids.items()}\n",
    "# firm_ids_str = {y:x for x, y in firm_ids_str.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to get 20-year averages\n",
    "def get_twenty_yr_avg(df, index_names, col_name, firm_ids_str):\n",
    "    df = pd.DataFrame({col_name : df[index_names].mean()}).rename_axis('firm_id').reset_index()\n",
    "    df['firm_id'] = df['firm_id'].map(firm_ids_str)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get 20-year averages\n",
    "eps_fc_twenty_avg = get_twenty_yr_avg(eps_fc_clean, firm_names, 'eps_fc', firm_ids_str)\n",
    "eps_act_twenty_avg = get_twenty_yr_avg(eps_act_clean, firm_names, 'eps_act', firm_ids_str)\n",
    "eod_act_twenty_avg = get_twenty_yr_avg(eod_act_clean, firm_names, 'eod_act', firm_ids_str)\n",
    "eps_fc_terms_twenty_avg = get_twenty_yr_avg(eps_fc_terms_clean, firm_names, 'eps_fc_terms', firm_ids_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put averages into a list\n",
    "twenty_avg_list = [eps_fc_twenty_avg,\n",
    "                  eps_act_twenty_avg,\n",
    "                  eod_act_twenty_avg,\n",
    "                  eps_fc_terms_twenty_avg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all Series\n",
    "df_twenty_year_avgs = reduce(lambda x, y: pd.merge(x, y, on = 'firm_id', how = 'outer'), twenty_avg_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>eps_fc</th>\n",
       "      <th>eps_act</th>\n",
       "      <th>eod_act</th>\n",
       "      <th>eps_fc_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>461</td>\n",
       "      <td>1.011390</td>\n",
       "      <td>0.824578</td>\n",
       "      <td>79.508100</td>\n",
       "      <td>1.079532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>296</td>\n",
       "      <td>0.336036</td>\n",
       "      <td>0.366125</td>\n",
       "      <td>22.804390</td>\n",
       "      <td>0.405065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>0.407952</td>\n",
       "      <td>0.383253</td>\n",
       "      <td>32.041625</td>\n",
       "      <td>0.440250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>364</td>\n",
       "      <td>0.690274</td>\n",
       "      <td>0.691766</td>\n",
       "      <td>40.314272</td>\n",
       "      <td>0.730132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>141</td>\n",
       "      <td>0.373815</td>\n",
       "      <td>0.203342</td>\n",
       "      <td>22.501463</td>\n",
       "      <td>0.385870</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    firm_id    eps_fc   eps_act    eod_act  eps_fc_terms\n",
       "461     461  1.011390  0.824578  79.508100      1.079532\n",
       "296     296  0.336036  0.366125  22.804390      0.405065\n",
       "405     405  0.407952  0.383253  32.041625      0.440250\n",
       "364     364  0.690274  0.691766  40.314272      0.730132\n",
       "141     141  0.373815  0.203342  22.501463      0.385870"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twenty_year_avgs.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check there are 505 firms\n",
    "df_twenty_year_avgs.firm_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "firm_id         False\n",
       "eps_fc          False\n",
       "eps_act          True\n",
       "eod_act         False\n",
       "eps_fc_terms     True\n",
       "dtype: bool"
      ]
     },
     "execution_count": 363,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check missing data\n",
    "df_twenty_year_avgs.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 364,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check duplicate data\n",
    "df_twenty_year_avgs.duplicated().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "> **ISSUE 8:** No recorded yearly averages for each dataset.\n",
    "\n",
    "**Define:**\n",
    "- Create 4 separate DataFrames for all attributes\n",
    "- Rename columns to \"Feature_Year\" (e.g. eps_fc_1999, eod_act_2000, etc.)\n",
    "- Outer merge all DataFrames to create new DataFrame, `df_yearly_avgs`, on **firms** attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to calculate yearly average of each DataFrame\n",
    "def calculate_df_yearly_avgs(df, col, firm_ids_str):\n",
    "    #extract year from dates, reset index, and remove index name\n",
    "    df = df.groupby(df[col].dt.year).mean().transpose().rename_axis('firm_id').reset_index().rename_axis(None, axis = 1)\n",
    "    \n",
    "    df['firm_id'] = df['firm_id'].map(firm_ids_str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to melt columns\n",
    "def melt_avgs(df, firm_id, var_name):\n",
    "    return df.melt(id_vars = [firm_id],\n",
    "                value_vars = df.columns.difference([firm_id]),\n",
    "                var_name = var_name,\n",
    "                value_name = 'average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate and melt\n",
    "def create_df_yearly_avgs(df, col, firm_ids_str, firm_id):\n",
    "    df = calculate_df_yearly_avgs(df, 'term_forecast', firm_ids_str)\n",
    "    df = melt_avgs(df, firm_id, 'year')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate DataFrames of all yearly averages\n",
    "eps_fc_yearly_avgs = create_df_yearly_avgs(eps_fc_clean, 'term_forecast', firm_ids_str, 'firm_id')\n",
    "eps_act_yearly_avgs = create_df_yearly_avgs(eps_act_clean, 'term_forecast', firm_ids_str, 'firm_id')\n",
    "\n",
    "#for eod_act, doesn't matter if we use date or term_forecast field\n",
    "eod_act_yearly_avgs = create_df_yearly_avgs(eod_act_clean, 'date', firm_ids_str, 'firm_id')\n",
    "eps_fc_terms_yearly_avgs = create_df_yearly_avgs(eps_fc_terms_clean, 'term_forecast', firm_ids_str, 'firm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_df(path, df, csv_name):\n",
    "    df.to_csv(path + csv_name, encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store yearly averages\n",
    "store_df(PATH_CLEAN_AVGS_SUB, eps_fc_yearly_avgs, 'yearly-avgs-eps-fc.csv')\n",
    "store_df(PATH_CLEAN_AVGS_SUB, eps_act_yearly_avgs, 'yearly-avgs-eps-act.csv')\n",
    "store_df(PATH_CLEAN_AVGS_SUB, eod_act_yearly_avgs, 'yearly-avgs-eod-act.csv')\n",
    "store_df(PATH_CLEAN_AVGS_SUB, eps_fc_terms_yearly_avgs, 'yearly-avgs-eps-fc-terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new column entailing \"type\" of feature before concat\n",
    "eps_fc_yearly_avgs = eps_fc_yearly_avgs.assign(feature = 'eps_fc')\n",
    "eps_act_yearly_avgs = eps_act_yearly_avgs.assign(feature = 'eps_act')\n",
    "eod_act_yearly_avgs = eod_act_yearly_avgs.assign(feature = 'eod_act')\n",
    "eps_fc_terms_yearly_avgs = eps_fc_terms_yearly_avgs.assign(feature = 'eps_fc_terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "yearly_avgs_arr = [eps_fc_yearly_avgs, \n",
    "                  eps_act_yearly_avgs,\n",
    "                  eod_act_yearly_avgs,\n",
    "                  eps_fc_terms_yearly_avgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all yearly average DataFrames\n",
    "df_yearly_avgs = pd.concat(yearly_avgs_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>year</th>\n",
       "      <th>average</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6524</th>\n",
       "      <td>464</td>\n",
       "      <td>2011</td>\n",
       "      <td>1.34600</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>752</th>\n",
       "      <td>247</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5313</th>\n",
       "      <td>263</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.30050</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2720</th>\n",
       "      <td>195</td>\n",
       "      <td>2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8983</th>\n",
       "      <td>398</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.87000</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6354</th>\n",
       "      <td>294</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.34350</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>445</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8312</th>\n",
       "      <td>232</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.50600</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4709</th>\n",
       "      <td>164</td>\n",
       "      <td>2008</td>\n",
       "      <td>0.91500</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6851</th>\n",
       "      <td>286</td>\n",
       "      <td>2012</td>\n",
       "      <td>1.70525</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     firm_id  year  average feature\n",
       "6524     464  2011  1.34600  eps_fc\n",
       "752      247  2000      NaN  eps_fc\n",
       "5313     263  2009  0.30050  eps_fc\n",
       "2720     195  2004      NaN  eps_fc\n",
       "8983     398  2016  0.87000  eps_fc\n",
       "6354     294  2011  0.34350  eps_fc\n",
       "1960     445  2002      NaN  eps_fc\n",
       "8312     232  2015  0.50600  eps_fc\n",
       "4709     164  2008  0.91500  eps_fc\n",
       "6851     286  2012  1.70525  eps_fc"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each average, individually\n",
    "\n",
    "#eps_fc_yearly\n",
    "eps_fc_yearly_avgs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>year</th>\n",
       "      <th>average</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7778</th>\n",
       "      <td>203</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.990000</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5351</th>\n",
       "      <td>301</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.280038</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5385</th>\n",
       "      <td>335</td>\n",
       "      <td>2009</td>\n",
       "      <td>-0.093750</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7532</th>\n",
       "      <td>462</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.987500</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1360</th>\n",
       "      <td>350</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.090637</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9626</th>\n",
       "      <td>31</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.787500</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9539</th>\n",
       "      <td>449</td>\n",
       "      <td>2017</td>\n",
       "      <td>-0.039320</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5979</th>\n",
       "      <td>424</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.817500</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6134</th>\n",
       "      <td>74</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.342500</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9194</th>\n",
       "      <td>104</td>\n",
       "      <td>2017</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     firm_id  year   average  feature\n",
       "7778     203  2014  1.990000  eps_act\n",
       "5351     301  2009  0.280038  eps_act\n",
       "5385     335  2009 -0.093750  eps_act\n",
       "7532     462  2013  0.987500  eps_act\n",
       "1360     350  2001  0.090637  eps_act\n",
       "9626      31  2018  0.787500  eps_act\n",
       "9539     449  2017 -0.039320  eps_act\n",
       "5979     424  2010  0.817500  eps_act\n",
       "6134      74  2011  0.342500  eps_act\n",
       "9194     104  2017  1.200000  eps_act"
      ]
     },
     "execution_count": 375,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eps_fc_yearly\n",
    "eps_act_yearly_avgs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>year</th>\n",
       "      <th>average</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5769</th>\n",
       "      <td>214</td>\n",
       "      <td>2010</td>\n",
       "      <td>153.660000</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5940</th>\n",
       "      <td>385</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6550</th>\n",
       "      <td>490</td>\n",
       "      <td>2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3257</th>\n",
       "      <td>227</td>\n",
       "      <td>2005</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1943</th>\n",
       "      <td>428</td>\n",
       "      <td>2002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3788</th>\n",
       "      <td>253</td>\n",
       "      <td>2006</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7292</th>\n",
       "      <td>222</td>\n",
       "      <td>2013</td>\n",
       "      <td>76.360000</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5898</th>\n",
       "      <td>343</td>\n",
       "      <td>2010</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1915</th>\n",
       "      <td>400</td>\n",
       "      <td>2002</td>\n",
       "      <td>8.043750</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8076</th>\n",
       "      <td>501</td>\n",
       "      <td>2014</td>\n",
       "      <td>54.184325</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     firm_id  year     average  feature\n",
       "5769     214  2010  153.660000  eod_act\n",
       "5940     385  2010         NaN  eod_act\n",
       "6550     490  2011         NaN  eod_act\n",
       "3257     227  2005         NaN  eod_act\n",
       "1943     428  2002         NaN  eod_act\n",
       "3788     253  2006         NaN  eod_act\n",
       "7292     222  2013   76.360000  eod_act\n",
       "5898     343  2010         NaN  eod_act\n",
       "1915     400  2002    8.043750  eod_act\n",
       "8076     501  2014   54.184325  eod_act"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eod_act_yearly\n",
    "eod_act_yearly_avgs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>year</th>\n",
       "      <th>average</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6071</th>\n",
       "      <td>11</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.79825</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8833</th>\n",
       "      <td>248</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.69775</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6338</th>\n",
       "      <td>278</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.23825</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5655</th>\n",
       "      <td>100</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.37450</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5111</th>\n",
       "      <td>61</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.04700</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7454</th>\n",
       "      <td>384</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.28550</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8547</th>\n",
       "      <td>467</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.86400</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7402</th>\n",
       "      <td>332</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.65900</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>63</td>\n",
       "      <td>2003</td>\n",
       "      <td>0.28900</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2788</th>\n",
       "      <td>263</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.20425</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     firm_id  year  average       feature\n",
       "6071      11  2012  0.79825  eps_fc_terms\n",
       "8833     248  2017  0.69775  eps_fc_terms\n",
       "6338     278  2012  0.23825  eps_fc_terms\n",
       "5655     100  2011  0.37450  eps_fc_terms\n",
       "5111      61  2010  1.04700  eps_fc_terms\n",
       "7454     384  2014  1.28550  eps_fc_terms\n",
       "8547     467  2016  0.86400  eps_fc_terms\n",
       "7402     332  2014  0.65900  eps_fc_terms\n",
       "1578      63  2003  0.28900  eps_fc_terms\n",
       "2788     263  2005  0.20425  eps_fc_terms"
      ]
     },
     "execution_count": 377,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eps_fc_terms_yearly\n",
    "eps_fc_terms_yearly_avgs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['firm_id', 'year', 'average', 'feature'], dtype='object') \n",
      " Index(['firm_id', 'year', 'average', 'feature'], dtype='object') \n",
      " Index(['firm_id', 'year', 'average', 'feature'], dtype='object') \n",
      " Index(['firm_id', 'year', 'average', 'feature'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#verify all columns are consistent\n",
    "print(eps_fc_yearly_avgs.columns, '\\n',\n",
    "      eps_act_yearly_avgs.columns, '\\n',\n",
    "      eod_act_yearly_avgs.columns, '\\n',\n",
    "      eps_fc_terms_yearly_avgs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505 \n",
      " 505 \n",
      " 505 \n",
      " 505\n"
     ]
    }
   ],
   "source": [
    "#verify there are 505 firms in each dataframe\n",
    "print(eps_fc_yearly_avgs.firm_id.nunique(), '\\n',\n",
    "      eps_act_yearly_avgs.firm_id.nunique(), '\\n',\n",
    "      eod_act_yearly_avgs.firm_id.nunique(), '\\n',\n",
    "      eps_fc_terms_yearly_avgs.firm_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>year</th>\n",
       "      <th>average</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8482</th>\n",
       "      <td>402</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.118333</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>332</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>39</td>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>238</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8871</th>\n",
       "      <td>286</td>\n",
       "      <td>2017</td>\n",
       "      <td>2.404750</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5582</th>\n",
       "      <td>27</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.435250</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10235</th>\n",
       "      <td>135</td>\n",
       "      <td>2019</td>\n",
       "      <td>2.162750</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1383</th>\n",
       "      <td>373</td>\n",
       "      <td>2001</td>\n",
       "      <td>15.582500</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3463</th>\n",
       "      <td>433</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.508750</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5063</th>\n",
       "      <td>13</td>\n",
       "      <td>2010</td>\n",
       "      <td>1.523250</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      firm_id  year    average       feature\n",
       "8482      402  2015   0.118333       eps_act\n",
       "332       332  2000        NaN  eps_fc_terms\n",
       "39         39  2000        NaN  eps_fc_terms\n",
       "1248      238  2001   0.190000       eps_act\n",
       "8871      286  2017   2.404750  eps_fc_terms\n",
       "5582       27  2011   0.435250  eps_fc_terms\n",
       "10235     135  2019   2.162750        eps_fc\n",
       "1383      373  2001  15.582500       eod_act\n",
       "3463      433  2005   0.508750        eps_fc\n",
       "5063       13  2010   1.523250  eps_fc_terms"
      ]
     },
     "execution_count": 380,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all yearly averages\n",
    "df_yearly_avgs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify 505 firms in all yearly averages df\n",
    "df_yearly_avgs.firm_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    "\n",
    "> **ISSUE 9:** No recorded quarterly averages for each dataset.\n",
    "\n",
    "**Define:** \n",
    "\n",
    "- Parse `eod_act_clean` dates  by **calendar quarter average** with quarterly data in a new DataFrame.\n",
    "- Create separate DataFrames containing quarterly averages for `eps_fc_clean`, `eps_act_clean`, and `eps_fc_terms_clean` \n",
    "- Rename columns to \"Quarter_Year_Feature\" (e.g. **q1_eps_fc,** etc.)\n",
    "- Outer merge all DataFrames into a new df `df_quarterly_avgs` on **firms**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper function to calculate quarterly average of each DataFrame\n",
    "def calculate_df_quarterly_avgs(df, col, firm_ids_str):\n",
    "    #extract quarter from Period objects\n",
    "    df =  df.groupby(df[col].dt.strftime('Q%q')).mean().transpose().rename_axis('firm_id').reset_index().rename_axis(None, axis = 1)\n",
    "    df['firm_id'] = df['firm_id'].map(firm_ids_str)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate and melt\n",
    "def create_df_quarterly_avgs(df, col, firm_ids_str, firm_id):\n",
    "    df = calculate_df_quarterly_avgs(df, 'term_forecast', firm_ids_str)\n",
    "    df = melt_avgs(df, firm_id, 'quarter')\n",
    "    \n",
    "    #lowercase quarter column\n",
    "    df.quarter = df.quarter.str.lower()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate all quarterly average DataFrames\n",
    "eps_fc_quarter_avgs = create_df_quarterly_avgs(eps_fc_clean, 'term_forecast', firm_ids_str, 'firm_id')\n",
    "eps_act_quarter_avgs = create_df_quarterly_avgs(eps_act_clean, 'term_forecast', firm_ids_str, 'firm_id')\n",
    "eod_act_quarter_avgs = create_df_quarterly_avgs(eod_act_clean, 'term_forecast', firm_ids_str, 'firm_id')\n",
    "eps_fc_terms_quarter_avgs = create_df_quarterly_avgs(eps_fc_terms_clean, 'term_forecast', firm_ids_str, 'firm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "#store quarterly averages\n",
    "store_df(PATH_CLEAN_AVGS_SUB, eps_fc_quarter_avgs, 'quarter-avgs-eps-fc.csv')\n",
    "store_df(PATH_CLEAN_AVGS_SUB, eps_act_quarter_avgs, 'quarter-avgs-eps-act.csv')\n",
    "store_df(PATH_CLEAN_AVGS_SUB, eod_act_quarter_avgs, 'quarter-avgs-eod-act.csv')\n",
    "store_df(PATH_CLEAN_AVGS_SUB, eps_fc_terms_quarter_avgs, 'quarter-avgs-eps-fc-terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new column entailing \"type\" of feature before concat\n",
    "eps_fc_quarter_avgs = eps_fc_quarter_avgs.assign(feature = 'eps_fc')\n",
    "eps_act_quarter_avgs = eps_act_quarter_avgs.assign(feature = 'eps_act')\n",
    "eod_act_quarter_avgs = eod_act_quarter_avgs.assign(feature = 'eod_act')\n",
    "eps_fc_terms_quarter_avgs = eps_fc_terms_quarter_avgs.assign(feature = 'eps_fc_terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put DataFrames in array\n",
    "quarterly_avgs_arr = [eps_fc_quarter_avgs,\n",
    "                  eps_act_quarter_avgs,\n",
    "                  eod_act_quarter_avgs,\n",
    "                  eps_fc_terms_quarter_avgs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge all quarterly average DataFrames\n",
    "df_quarter_avgs = pd.concat(quarterly_avgs_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>quarter</th>\n",
       "      <th>average</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>448</td>\n",
       "      <td>q4</td>\n",
       "      <td>0.188000</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>160</td>\n",
       "      <td>q4</td>\n",
       "      <td>0.571143</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>846</th>\n",
       "      <td>341</td>\n",
       "      <td>q2</td>\n",
       "      <td>0.132667</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1684</th>\n",
       "      <td>169</td>\n",
       "      <td>q4</td>\n",
       "      <td>-0.798095</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>411</th>\n",
       "      <td>411</td>\n",
       "      <td>q1</td>\n",
       "      <td>0.964810</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>4</td>\n",
       "      <td>q3</td>\n",
       "      <td>1.361571</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>349</td>\n",
       "      <td>q4</td>\n",
       "      <td>0.834762</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>80</td>\n",
       "      <td>q1</td>\n",
       "      <td>0.334476</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>444</td>\n",
       "      <td>q1</td>\n",
       "      <td>0.670952</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1359</th>\n",
       "      <td>349</td>\n",
       "      <td>q3</td>\n",
       "      <td>0.825905</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     firm_id quarter   average feature\n",
       "1963     448      q4  0.188000  eps_fc\n",
       "1675     160      q4  0.571143  eps_fc\n",
       "846      341      q2  0.132667  eps_fc\n",
       "1684     169      q4 -0.798095  eps_fc\n",
       "411      411      q1  0.964810  eps_fc\n",
       "1014       4      q3  1.361571  eps_fc\n",
       "1864     349      q4  0.834762  eps_fc\n",
       "80        80      q1  0.334476  eps_fc\n",
       "444      444      q1  0.670952  eps_fc\n",
       "1359     349      q3  0.825905  eps_fc"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#each quarter individually\n",
    "\n",
    "#eps_fc_quarter\n",
    "eps_fc_quarter_avgs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>quarter</th>\n",
       "      <th>average</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>500</td>\n",
       "      <td>q2</td>\n",
       "      <td>0.481000</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1905</th>\n",
       "      <td>390</td>\n",
       "      <td>q4</td>\n",
       "      <td>0.426548</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1675</th>\n",
       "      <td>160</td>\n",
       "      <td>q4</td>\n",
       "      <td>-0.127061</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>98</td>\n",
       "      <td>q1</td>\n",
       "      <td>-0.344944</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1577</th>\n",
       "      <td>62</td>\n",
       "      <td>q4</td>\n",
       "      <td>0.668000</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>481</td>\n",
       "      <td>q2</td>\n",
       "      <td>0.406667</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1149</th>\n",
       "      <td>139</td>\n",
       "      <td>q3</td>\n",
       "      <td>0.643214</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1824</th>\n",
       "      <td>309</td>\n",
       "      <td>q4</td>\n",
       "      <td>0.416160</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>q1</td>\n",
       "      <td>1.176667</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>344</td>\n",
       "      <td>q1</td>\n",
       "      <td>1.768095</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     firm_id quarter   average  feature\n",
       "1005     500      q2  0.481000  eps_act\n",
       "1905     390      q4  0.426548  eps_act\n",
       "1675     160      q4 -0.127061  eps_act\n",
       "98        98      q1 -0.344944  eps_act\n",
       "1577      62      q4  0.668000  eps_act\n",
       "986      481      q2  0.406667  eps_act\n",
       "1149     139      q3  0.643214  eps_act\n",
       "1824     309      q4  0.416160  eps_act\n",
       "497      497      q1  1.176667  eps_act\n",
       "344      344      q1  1.768095  eps_act"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eps_act_quarter\n",
    "eps_act_quarter_avgs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>quarter</th>\n",
       "      <th>average</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>360</td>\n",
       "      <td>q3</td>\n",
       "      <td>105.514857</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1830</th>\n",
       "      <td>315</td>\n",
       "      <td>q4</td>\n",
       "      <td>52.245565</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1322</th>\n",
       "      <td>312</td>\n",
       "      <td>q3</td>\n",
       "      <td>38.874545</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>483</td>\n",
       "      <td>q1</td>\n",
       "      <td>46.210952</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>421</td>\n",
       "      <td>q2</td>\n",
       "      <td>63.735000</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1087</th>\n",
       "      <td>77</td>\n",
       "      <td>q3</td>\n",
       "      <td>24.988662</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>377</td>\n",
       "      <td>q1</td>\n",
       "      <td>72.662619</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1378</th>\n",
       "      <td>368</td>\n",
       "      <td>q3</td>\n",
       "      <td>57.865000</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1690</th>\n",
       "      <td>175</td>\n",
       "      <td>q4</td>\n",
       "      <td>37.172625</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>59</td>\n",
       "      <td>q1</td>\n",
       "      <td>103.468238</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     firm_id quarter     average  feature\n",
       "1370     360      q3  105.514857  eod_act\n",
       "1830     315      q4   52.245565  eod_act\n",
       "1322     312      q3   38.874545  eod_act\n",
       "483      483      q1   46.210952  eod_act\n",
       "926      421      q2   63.735000  eod_act\n",
       "1087      77      q3   24.988662  eod_act\n",
       "377      377      q1   72.662619  eod_act\n",
       "1378     368      q3   57.865000  eod_act\n",
       "1690     175      q4   37.172625  eod_act\n",
       "59        59      q1  103.468238  eod_act"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eod_act_quarter\n",
    "eod_act_quarter_avgs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>quarter</th>\n",
       "      <th>average</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>500</td>\n",
       "      <td>q2</td>\n",
       "      <td>0.574625</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>381</td>\n",
       "      <td>q4</td>\n",
       "      <td>0.510800</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1501</th>\n",
       "      <td>491</td>\n",
       "      <td>q3</td>\n",
       "      <td>0.401769</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1736</th>\n",
       "      <td>221</td>\n",
       "      <td>q4</td>\n",
       "      <td>0.305357</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>q1</td>\n",
       "      <td>0.636929</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1163</th>\n",
       "      <td>153</td>\n",
       "      <td>q3</td>\n",
       "      <td>0.914750</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>465</td>\n",
       "      <td>q1</td>\n",
       "      <td>0.585273</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>585</th>\n",
       "      <td>80</td>\n",
       "      <td>q2</td>\n",
       "      <td>0.486200</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>424</th>\n",
       "      <td>424</td>\n",
       "      <td>q1</td>\n",
       "      <td>0.717000</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1534</th>\n",
       "      <td>19</td>\n",
       "      <td>q4</td>\n",
       "      <td>2.274333</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     firm_id quarter   average       feature\n",
       "1005     500      q2  0.574625  eps_fc_terms\n",
       "1896     381      q4  0.510800  eps_fc_terms\n",
       "1501     491      q3  0.401769  eps_fc_terms\n",
       "1736     221      q4  0.305357  eps_fc_terms\n",
       "10        10      q1  0.636929  eps_fc_terms\n",
       "1163     153      q3  0.914750  eps_fc_terms\n",
       "465      465      q1  0.585273  eps_fc_terms\n",
       "585       80      q2  0.486200  eps_fc_terms\n",
       "424      424      q1  0.717000  eps_fc_terms\n",
       "1534      19      q4  2.274333  eps_fc_terms"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#eps_fc_terms_quarter\n",
    "eps_fc_terms_quarter_avgs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['firm_id', 'quarter', 'average', 'feature'], dtype='object') \n",
      " Index(['firm_id', 'quarter', 'average', 'feature'], dtype='object') \n",
      " Index(['firm_id', 'quarter', 'average', 'feature'], dtype='object') \n",
      " Index(['firm_id', 'quarter', 'average', 'feature'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#verify that all columns are consistent\n",
    "print(eps_fc_quarter_avgs.columns, '\\n',\n",
    "      eps_act_quarter_avgs.columns, '\\n',\n",
    "      eod_act_quarter_avgs.columns, '\\n',\n",
    "      eps_fc_terms_quarter_avgs.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "505 \n",
      " 505 \n",
      " 505 \n",
      " 505\n"
     ]
    }
   ],
   "source": [
    "#verify there are 505 firms in each dataframe\n",
    "print(eps_fc_quarter_avgs.firm_id.nunique(), '\\n',\n",
    "      eps_act_quarter_avgs.firm_id.nunique(), '\\n',\n",
    "      eod_act_quarter_avgs.firm_id.nunique(), '\\n',\n",
    "      eps_fc_terms_quarter_avgs.firm_id.nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>quarter</th>\n",
       "      <th>average</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>391</td>\n",
       "      <td>q1</td>\n",
       "      <td>0.018333</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>236</td>\n",
       "      <td>q1</td>\n",
       "      <td>28.787095</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1429</th>\n",
       "      <td>419</td>\n",
       "      <td>q3</td>\n",
       "      <td>0.780227</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1880</th>\n",
       "      <td>365</td>\n",
       "      <td>q4</td>\n",
       "      <td>0.506700</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>96</td>\n",
       "      <td>q1</td>\n",
       "      <td>22.507162</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>839</th>\n",
       "      <td>334</td>\n",
       "      <td>q2</td>\n",
       "      <td>33.074545</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1770</th>\n",
       "      <td>255</td>\n",
       "      <td>q4</td>\n",
       "      <td>23.448665</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>957</th>\n",
       "      <td>452</td>\n",
       "      <td>q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>343</td>\n",
       "      <td>q1</td>\n",
       "      <td>0.079934</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>460</td>\n",
       "      <td>q1</td>\n",
       "      <td>0.802941</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     firm_id quarter    average       feature\n",
       "391      391      q1   0.018333       eps_act\n",
       "236      236      q1  28.787095       eod_act\n",
       "1429     419      q3   0.780227       eps_act\n",
       "1880     365      q4   0.506700        eps_fc\n",
       "96        96      q1  22.507162       eod_act\n",
       "839      334      q2  33.074545       eod_act\n",
       "1770     255      q4  23.448665       eod_act\n",
       "957      452      q2        NaN       eps_act\n",
       "343      343      q1   0.079934       eps_act\n",
       "460      460      q1   0.802941  eps_fc_terms"
      ]
     },
     "execution_count": 395,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#all quarterly averages\n",
    "df_quarter_avgs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify 505 firms in df_quarter_avgs\n",
    "df_quarter_avgs.firm_id.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>eps_fc</th>\n",
       "      <th>eps_act</th>\n",
       "      <th>eod_act</th>\n",
       "      <th>eps_fc_terms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.531678</td>\n",
       "      <td>0.352169</td>\n",
       "      <td>32.896718</td>\n",
       "      <td>0.567579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.339879</td>\n",
       "      <td>-0.388520</td>\n",
       "      <td>40.303125</td>\n",
       "      <td>0.709745</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  firm_id    eps_fc   eps_act    eod_act  eps_fc_terms\n",
       "0       0  0.531678  0.352169  32.896718      0.567579\n",
       "1       1  0.339879 -0.388520  40.303125      0.709745"
      ]
     },
     "execution_count": 397,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_twenty_year_avgs.head(2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    ">**ISSUE 10:** Unnormalized data among `df_twenty_year_avgs`, `df_yearly_avgs`, and `df_quarter_avgs`\n",
    "\n",
    "**Define:** \n",
    "- Normalize features across all 3 DataFrames. \n",
    "- For `df_twenty_year_avgs`, melt **feature column names** (eps_fc, eps_act, eod_act, eps_fc_terms) into a single column called **feature**\n",
    "\n",
    "Desired output for each DataFrame:\n",
    "\n",
    "\n",
    "| firm_id     | average  | average_type | time_period   | feature|\n",
    "|:------------|:-------------:|:-----------:|:---------:|-------:|\n",
    "|43           | 3.14          | quarterly   | q1        | eps_fc |\n",
    "\n",
    "> ***Apply the above table format to all three DFs, then concatenate to create `all_avgs` .***\n",
    "\n",
    "**Note:** For `df_twenty_year_avgs`, it would be redundant to put *twenty_year* as the value under both **average_type** and **time_period** columns.\n",
    "\n",
    "To curb this, I will assign all **time_period** values as NaN for `df_twenty_year_avgs`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign column order\n",
    "avgs_col_order = ['firm_id', 'average', 'average_type', 'time_period', 'feature']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create clean copies of dfs\n",
    "twenty_year_clean = df_twenty_year_avgs.copy()\n",
    "yearly_clean = df_yearly_avgs.copy()\n",
    "quarterly_clean = df_quarter_avgs.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### `twenty_year_clean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "#isolate feature names\n",
    "feats_col_names = twenty_year_clean.columns.difference(['firm_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "#move eps_fc . . . eps_fc_terms under \"average_type\"\n",
    "twenty_year_clean = pd.melt(twenty_year_clean,\n",
    "        id_vars = ['firm_id'],\n",
    "        value_vars = feats_col_names,\n",
    "        var_name = 'feature',\n",
    "        value_name = 'average')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add 'feature' and 'time_period' columns\n",
    "twenty_year_clean = twenty_year_clean.assign(average_type = 'twenty_year', time_period = np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder columns\n",
    "twenty_year_clean = twenty_year_clean[avgs_col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### `yearly_clean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign 'average_type' column\n",
    "yearly_clean = yearly_clean.assign(average_type = 'yearly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename 'year' column to 'time_period'\n",
    "yearly_clean.rename(columns = {'year' : 'time_period'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder columns\n",
    "yearly_clean = yearly_clean[avgs_col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### `quarterly_clean`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign 'average_type' column\n",
    "quarterly_clean = quarterly_clean.assign(average_type = 'quarterly')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename 'quarter' column to 'time_period'\n",
    "quarterly_clean.rename(columns = {'quarter' : 'time_period'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder columns\n",
    "quarterly_clean = quarterly_clean[avgs_col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    ">**ISSUE 11:** - 20-year, yearly, and quarterly averages contained in different DataFrames.\n",
    "\n",
    "**Define:** Concatenate the normalized `twenty_year_clean`, `yearly_clean`, and `quarterly_clean` into new CSV **all_avgs.csv**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put all average DFs in an array\n",
    "avgs_array = [twenty_year_clean, yearly_clean, quarterly_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_avgs = pd.concat(avgs_array)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>average</th>\n",
       "      <th>average_type</th>\n",
       "      <th>time_period</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4188</th>\n",
       "      <td>148</td>\n",
       "      <td>34.757500</td>\n",
       "      <td>yearly</td>\n",
       "      <td>2007</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>693</th>\n",
       "      <td>188</td>\n",
       "      <td>0.066250</td>\n",
       "      <td>yearly</td>\n",
       "      <td>2001</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>14</td>\n",
       "      <td>0.205550</td>\n",
       "      <td>quarterly</td>\n",
       "      <td>q3</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>901</th>\n",
       "      <td>396</td>\n",
       "      <td>0.311397</td>\n",
       "      <td>twenty_year</td>\n",
       "      <td>NaN</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yearly</td>\n",
       "      <td>2000</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5409</th>\n",
       "      <td>359</td>\n",
       "      <td>0.393000</td>\n",
       "      <td>yearly</td>\n",
       "      <td>2010</td>\n",
       "      <td>eps_fc_terms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3208</th>\n",
       "      <td>178</td>\n",
       "      <td>9.787500</td>\n",
       "      <td>yearly</td>\n",
       "      <td>2005</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>76</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>yearly</td>\n",
       "      <td>2000</td>\n",
       "      <td>eps_act</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8561</th>\n",
       "      <td>481</td>\n",
       "      <td>1.871000</td>\n",
       "      <td>yearly</td>\n",
       "      <td>2015</td>\n",
       "      <td>eps_fc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6959</th>\n",
       "      <td>394</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yearly</td>\n",
       "      <td>2012</td>\n",
       "      <td>eod_act</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     firm_id    average average_type time_period       feature\n",
       "4188     148  34.757500       yearly        2007       eod_act\n",
       "693      188   0.066250       yearly        2001  eps_fc_terms\n",
       "1024      14   0.205550    quarterly          q3  eps_fc_terms\n",
       "901      396   0.311397  twenty_year         NaN       eps_act\n",
       "26        26        NaN       yearly        2000  eps_fc_terms\n",
       "5409     359   0.393000       yearly        2010  eps_fc_terms\n",
       "3208     178   9.787500       yearly        2005       eod_act\n",
       "581       76   0.115000       yearly        2000       eps_act\n",
       "8561     481   1.871000       yearly        2015        eps_fc\n",
       "6959     394        NaN       yearly        2012       eod_act"
      ]
     },
     "execution_count": 412,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_avgs.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52015, 5)"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify \n",
    "all_avgs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "505"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verify 505 firms, no duplicates\n",
    "all_avgs.firm_id.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code\n",
    ">**ISSUE 11:** Unnormalized data among `eps_act`, `eps_fc`, `eod_act`, and `eps_fc_terms`\n",
    "\n",
    "**Define:**\n",
    "\n",
    "- Achieve desired `features.csv` output:\n",
    "\n",
    "| firm_id  | term_forecast     | value      | feature         |    date    |\n",
    "|:---------| :-------: | :-----------------:| :-------------: |----------: |\n",
    "| 44       |     2004Q1  |  3.55           |        eps_fc      |  NaN      |\n",
    "| 55       | 2004Q4     |  6.22       |  eps_fc_terms       | 2004-07-01 |\n",
    "| 202      | 2015Q1      | 6.28      |   eod_act         |   1999-03-31    |\n",
    "\n",
    "\n",
    "> **date** feature contains the **date column in `eod_act`** and **forecast_made in `eps_fc_terms`**. They are assigned to the same column because both columns are consistent: the same DateTime Object.\n",
    "\n",
    "> **date** feature will be NaN for `eps_fc` and `eps_act`.\n",
    "\n",
    "- ### `eps_fc` and `eps_act`\n",
    "\n",
    "> For both DataFrames, we don't have to worry about handling the **date** column. That will be resolved later when merging all the DataFrames with `eod_act` and `eps_fc_terms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 471,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_act_order = ['firm_id', 'feature', 'term_forecast', 'value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "#melt firm names\n",
    "eps_fc_clean = eps_fc_clean.melt (id_vars = ['term_forecast'],\n",
    "                  var_name = 'firm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_act_clean = eps_act_clean.melt(id_vars = ['term_forecast'],\n",
    "                                  var_name = 'firm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reassign all firms to firm_id\n",
    "eps_fc_clean['firm_id'] = eps_fc_clean['firm_id'].map(firm_names_ids)\n",
    "eps_act_clean['firm_id'] = eps_act_clean['firm_id'].map(firm_names_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add feature column\n",
    "eps_fc_clean = eps_fc_clean.assign(feature = 'eps_fc')\n",
    "eps_act_clean = eps_act_clean.assign(feature = 'eps_act')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder columns\n",
    "eps_fc_clean = eps_fc_clean[fc_act_order]\n",
    "eps_act_clean = eps_act_clean[fc_act_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### `eod_act`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define column order\n",
    "feats_col_order = ['firm_id', 'feature', 'date', 'term_forecast', 'value']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "#melt firm ids\n",
    "eod_act_clean = eod_act_clean.melt(id_vars = ['date', 'term_forecast'],\n",
    "                  var_name = 'firm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reassign firm_ids\n",
    "eod_act_clean['firm_id'] = eod_act_clean['firm_id'].map(firm_names_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add feature column\n",
    "eod_act_clean = eod_act_clean.assign(feature = 'eod_act')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder columns \n",
    "eod_act_clean = eod_act_clean[feats_col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### `eps_fc_terms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "#melt firm ids\n",
    "eps_fc_terms_clean = eps_fc_terms_clean.melt(id_vars = ['forecast_made', 'term_forecast'],\n",
    "                       var_name = 'firm_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reassign firm ids\n",
    "eps_fc_terms_clean['firm_id'] = eps_fc_terms_clean['firm_id'].map(firm_names_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename forecast_made to date\n",
    "eps_fc_terms_clean = eps_fc_terms_clean.rename(columns = {'forecast_made' : 'date'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add feature column\n",
    "eps_fc_terms_clean = eps_fc_terms_clean.assign(feature = 'eps_fc_terms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reorder columns\n",
    "eps_fc_terms_clean = eps_fc_terms_clean[feats_col_order]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ### `features.csv`\n",
    "\n",
    "Now's the time to bring everything together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_array = [eps_fc_clean, eps_act_clean, eod_act_clean, eps_fc_terms_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "#concat to prepare for outer left merge\n",
    "eod_act_eps_terms = pd.concat([eod_act_clean, eps_fc_terms_clean], join = 'outer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "#outer join\n",
    "features = pd.concat([eod_act_eps_terms, eps_fc_clean], join = 'outer', sort = False)\n",
    "features = pd.concat([features, eps_act_clean], join = 'outer', sort = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>firm_id</th>\n",
       "      <th>feature</th>\n",
       "      <th>date</th>\n",
       "      <th>term_forecast</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9210</th>\n",
       "      <td>109</td>\n",
       "      <td>eps_act</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2012Q3</td>\n",
       "      <td>0.0175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15334</th>\n",
       "      <td>182</td>\n",
       "      <td>eod_act</td>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>2010Q3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6967</th>\n",
       "      <td>82</td>\n",
       "      <td>eod_act</td>\n",
       "      <td>2018-12-31</td>\n",
       "      <td>2018Q4</td>\n",
       "      <td>127.0700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6546</th>\n",
       "      <td>77</td>\n",
       "      <td>eod_act</td>\n",
       "      <td>2018-09-28</td>\n",
       "      <td>2018Q3</td>\n",
       "      <td>42.7800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17989</th>\n",
       "      <td>214</td>\n",
       "      <td>eps_fc</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2002Q2</td>\n",
       "      <td>1.0170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34112</th>\n",
       "      <td>406</td>\n",
       "      <td>eps_act</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2001Q1</td>\n",
       "      <td>-0.3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10178</th>\n",
       "      <td>121</td>\n",
       "      <td>eps_fc</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2002Q3</td>\n",
       "      <td>0.0910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29698</th>\n",
       "      <td>353</td>\n",
       "      <td>eod_act</td>\n",
       "      <td>2010-09-30</td>\n",
       "      <td>2010Q3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14473</th>\n",
       "      <td>172</td>\n",
       "      <td>eps_fc</td>\n",
       "      <td>NaT</td>\n",
       "      <td>2005Q2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12069</th>\n",
       "      <td>143</td>\n",
       "      <td>eod_act</td>\n",
       "      <td>2013-06-28</td>\n",
       "      <td>2013Q2</td>\n",
       "      <td>42.5200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       firm_id  feature       date term_forecast     value\n",
       "9210       109  eps_act        NaT        2012Q3    0.0175\n",
       "15334      182  eod_act 2010-09-30        2010Q3       NaN\n",
       "6967        82  eod_act 2018-12-31        2018Q4  127.0700\n",
       "6546        77  eod_act 2018-09-28        2018Q3   42.7800\n",
       "17989      214   eps_fc        NaT        2002Q2    1.0170\n",
       "34112      406  eps_act        NaT        2001Q1   -0.3600\n",
       "10178      121   eps_fc        NaT        2002Q3    0.0910\n",
       "29698      353  eod_act 2010-09-30        2010Q3       NaN\n",
       "14473      172   eps_fc        NaT        2005Q2       NaN\n",
       "12069      143  eod_act 2013-06-28        2013Q2   42.5200"
      ]
     },
     "execution_count": 483,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III) Store Data <a id = \"store\"></a>\n",
    "\n",
    "**Disclaimer:** I decided to put the following CSVs under the ***./data/clean/averages/components*** directory because they form *part* of the main CSVs under the ***./data/clean/averages*** directory:\n",
    "- `quarter-avgs-eod-act.csv`\n",
    "- `quarter-avgs-eps-act.csv`\n",
    "- `quarter-avgs-eps-fc.csv`\n",
    "- `quarter-avgs-eps-fc-terms.csv`\n",
    "\n",
    "> The above are all components of the `quarter-avgs.csv` under **/averages/**\n",
    "\n",
    "- `yearly-avgs-eod-act.csv`\n",
    "- `yearly-avgs-eps-act.csv`\n",
    "- `yearly-avgs-eps-fc.csv`\n",
    "- `yearly-avgs-eps-fc-terms.csv`\n",
    "\n",
    "> The above are all components of the `yearly-avgs.csv` under **/averages/**\n",
    "\n",
    "**Additionally, I decided to keep `avgs.csv` under the *./data/clean/averages/* directory.** Although this CSV containing all averages would be highly inefficient for the data exploration stage, I decided it would be best to keep it on hand for convenience.\n",
    "\n",
    "Using `avgs.csv` would mean having the parse through the column names to isolate 20-year, yearly, and quarterly averages, but all of that redundance can be avoided by simply focusing on the `twenty-year-avgs`, `yearly-avgs`, and `quarter-avgs` CSVs alone.\n",
    "\n",
    "## Firms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "firm_ids.to_csv(PATH_CLEAN + 'firms.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#twenty-year-averages\n",
    "df_twenty_year_avgs.to_csv(PATH_CLEAN_AVGS + 'twenty-year-avgs.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yearly averagas\n",
    "df_yearly_avgs.to_csv(PATH_CLEAN_AVGS + 'yearly-avgs.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "#quarterly averages\n",
    "df_quarter_avgs.to_csv(PATH_CLEAN_AVGS + 'quarter-avgs.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all averages\n",
    "all_avgs.to_csv(PATH_CLEAN_AVGS + 'avgs.csv', encoding = 'utf-8', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** For the twenty year, yearly, and quarterly datasets, I stored their old `df_` version instead of their new clean versions. \n",
    "> This is because their old versions are stored more efficiently as ***standalone*** CSVs, and were only modified to fit the larger `all_avgs` DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_fc_clean.to_csv(PATH_CLEAN + 'eps-fc.csv')\n",
    "eps_act_clean.to_csv(PATH_CLEAN + 'eps-act.csv')\n",
    "eod_act_clean.to_csv(PATH_CLEAN + 'eod-act.csv')\n",
    "eps_fc_terms_clean.to_csv(PATH_CLEAN + 'eps-fc-terms.csv')\n",
    "\n",
    "features.to_csv(PATH_CLEAN + 'features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IV) Notes\n",
    "\n",
    "\n",
    "\n",
    "- When dealing with the CSVs depicting averages, we need to keep in mind **missing data** in our interpretations.\n",
    "- I decided to put the years as columns under yearly average DF generation because: the amount of columns generated here, TK, would be less than the amount of \n",
    "\tfirms there are, 505. [TK link to a study showing how having too many columns take up memory vs rows]\n",
    "    \n",
    "- keep in mind that `eod_act` is based on **calendar years** not fiscal years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#convert notebook to HTML"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
