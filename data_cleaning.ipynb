{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents\n",
    "- [Introduction](#introduction)\n",
    "- [Data Wrangling](#wrangling)\n",
    "    - [Gather](#gather)\n",
    "    - [Import](#import)\n",
    "    - [Assess](#assess)\n",
    "    - [Clean](#clean)\n",
    "    - [Store](#store)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I) Introduction <a id = \"introduction\">\n",
    "\n",
    "**Broad question:** How do price forecasts for each firm in the S&P 2019 Index compare to their corresponding actual prices?\n",
    "\n",
    "**Approach:** Analyze difference in means between average forecast EPS and average actual EPS for each firm.\n",
    "\n",
    "I will be analyzing quarterly price returns within the past 20 years for the firms present in the S&P 500 2019 Index.\n",
    "\n",
    "> At first, I wanted to analyze the forecasted vs. actual price earnings of the S&P in its entirety for the past 20 years. However, considering that firms continuously enter and leave stock indices every year, there would be varying levels of inconsistencies and marginal errors when comparing annual S&P returns alone. To combat this problem, I have isolated these two approaches:\n",
    "- Analyze the historical earnings of *only* the firms present in the S&P 2019 Index\n",
    "- Keep track of all firms that were present in the S&P for the past 20 years. Keep track of how many times each firm appeared in the Index and for those with the least count, analyze them individually on how they differ from the firms that stayed for longer.\n",
    "\n",
    "[TK] HEre is a breakdown of my final clean CSV's features, TK.csv.\n",
    "\n",
    "## II) Data Wrangling <a id=\"wrangling\"></a>\n",
    "\n",
    "To gather the data depicted under the `./data` folder, I used Bloomberg Excel functions.\n",
    "\n",
    "### A) Gather <a id = \"gather\"></a>\n",
    "> **APPROACH 1:** Focus on the firms that appear in the 2019 S&P Index and analyze their forecasted vs. actual price earnings for the last 20 years.\n",
    "\n",
    "To ensure consistency in analysis among multiple firms, I divide both the forecasted and actual price earning dates by *calendar period* instead of fiscal period. This is because fiscal period differs by firm whereas calendar period is consistent by dates. \n",
    "\n",
    "#### Through the Bloomberg Excel functions, I gathered four datasets with different purposes:\n",
    "\n",
    "- historical forecasted EPS\n",
    "- historical actual EPS\n",
    "- historical actual EOD price\n",
    "- historical forecasted EPS relying on terms\n",
    "\n",
    "---\n",
    "Before delving into the data, let's define what above terms:\n",
    "\n",
    "**EPS**\n",
    "\n",
    "> EPS stands for ***Estimated Price Earnings.*** The formal definition of EPS given by Investopedia is this:\n",
    "\n",
    "Earnings per share is the portion of a company's profit that is allocated to each outstanding share of a common stock, serving as an indicator of the company's financial health.\n",
    "\n",
    "In other words, the EPS is a portion of the company's **net income** after all of their dividends are paid off. Dividends are profits that are paid out to shareholders of the company. EPS is one of the most useful and valuable financial measurements because they ***determine a stock's worth.*** The higher the stock, the more the company can pay out dividends to its shareholders, and the more net profit they are determined to generate.\n",
    "\n",
    "$$ EPS = \\frac{Net Income - Preferred Dividends}{Weighted Average Common Shares Outstanding}\\$$\n",
    "\n",
    "**EOD**\n",
    "\n",
    "> EOD stands for the ***End of Day*** price. For any given day, the EOD marks the ***price at which the stock was valued*** at the end of the day's trading period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './data/'\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### C) Importing the Data <a id = \"import\"></a>\n",
    "\n",
    "### Let's summarize the contents of the following DataFrames as we import them.\n",
    "> All DataFrames consist of the 505 firms found in the 2019 S&P Index with EPS and EOD data encompassing 20 years: from January 1999 until the December 2019.\n",
    "\n",
    "**Historic forecasted EPS**\n",
    "> According to Investopedia, consensus estimates is normally an average or median of all the forecasts from individual analysts tracking a particular stock. In this case, the consensus estimate is for ***EPS for each firm present in the index as of 2019.*** Forecasted EPS is calculated by ***quarterly earnings,*** usually by each firm's fiscal period. Estimates of quarterly earnings are published at the beginning of each quarterly period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historic forecasted EPS \n",
    "df_eps_fc = pd.read_csv(PATH + 'sp-eps-fc.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term Forecasted</th>\n",
       "      <th>A UN Equity</th>\n",
       "      <th>AAL UW Equity</th>\n",
       "      <th>AAP UN Equity</th>\n",
       "      <th>AAPL UW Equity</th>\n",
       "      <th>ABBV UN Equity</th>\n",
       "      <th>ABC UN Equity</th>\n",
       "      <th>ABMD UW Equity</th>\n",
       "      <th>ABT UN Equity</th>\n",
       "      <th>ACN UN Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL UW Equity</th>\n",
       "      <th>XLNX UW Equity</th>\n",
       "      <th>XOM UN Equity</th>\n",
       "      <th>XRAY UW Equity</th>\n",
       "      <th>XRX UN Equity</th>\n",
       "      <th>XYL UN Equity</th>\n",
       "      <th>YUM UN Equity</th>\n",
       "      <th>ZBH UN Equity</th>\n",
       "      <th>ZION UW Equity</th>\n",
       "      <th>ZTS UN Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1999Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.423</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.456</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.239</td>\n",
       "      <td>0.123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.123</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.622</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1999Q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.213</td>\n",
       "      <td>0.090</td>\n",
       "      <td>0.264</td>\n",
       "      <td>0.135</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.661</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1999Q3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.381</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.767</td>\n",
       "      <td>0.099</td>\n",
       "      <td>0.300</td>\n",
       "      <td>0.129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.171</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.693</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1999Q4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.432</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.164</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.667</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.441</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.283</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.436</td>\n",
       "      <td>0.138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.138</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.668</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 506 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Term Forecasted  A UN Equity  AAL UW Equity  AAP UN Equity  AAPL UW Equity  \\\n",
       "0          1999Q1          NaN            NaN            NaN           0.025   \n",
       "1          1999Q2          NaN            NaN            NaN           0.020   \n",
       "2          1999Q3          NaN            NaN            NaN           0.023   \n",
       "3          1999Q4          NaN            NaN            NaN           0.016   \n",
       "4            00Q1          NaN            NaN            NaN           0.032   \n",
       "\n",
       "   ABBV UN Equity  ABC UN Equity  ABMD UW Equity  ABT UN Equity  \\\n",
       "0             NaN            NaN           -0.10          0.423   \n",
       "1             NaN            NaN           -0.13          0.420   \n",
       "2             NaN            NaN           -0.11          0.381   \n",
       "3             NaN            NaN             NaN          0.432   \n",
       "4             NaN            NaN             NaN          0.441   \n",
       "\n",
       "   ACN UN Equity  ...  XEL UW Equity  XLNX UW Equity  XOM UN Equity  \\\n",
       "0            NaN  ...          0.456           0.090          0.239   \n",
       "1            NaN  ...          0.213           0.090          0.264   \n",
       "2            NaN  ...          0.767           0.099          0.300   \n",
       "3            NaN  ...          0.432           0.124          0.386   \n",
       "4            NaN  ...          0.283           0.143          0.436   \n",
       "\n",
       "   XRAY UW Equity  XRX UN Equity  XYL UN Equity  YUM UN Equity  ZBH UN Equity  \\\n",
       "0           0.123            NaN            NaN          0.123            NaN   \n",
       "1           0.135            NaN            NaN          0.150            NaN   \n",
       "2           0.129            NaN            NaN          0.171            NaN   \n",
       "3           0.178            NaN            NaN          0.164            NaN   \n",
       "4           0.138            NaN            NaN          0.138            NaN   \n",
       "\n",
       "   ZION UW Equity  ZTS UN Equity  \n",
       "0           0.622            NaN  \n",
       "1           0.661            NaN  \n",
       "2           0.693            NaN  \n",
       "3           0.667            NaN  \n",
       "4           0.668            NaN  \n",
       "\n",
       "[5 rows x 506 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eps_fc.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Historic actual EPS**\n",
    "> Unlike forecasted EPS, actual EPS are the real numbers denoting Earnings-per-Share for a singular firm. Historic actual EPS will be compared to forecasted EPS to draw correlations and comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historic actual EPS\n",
    "df_eps_act = pd.read_csv(PATH + 'sp-eps-act.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Quarter</th>\n",
       "      <th>Year</th>\n",
       "      <th>A UN Equity</th>\n",
       "      <th>AAL UW Equity</th>\n",
       "      <th>AAP UN Equity</th>\n",
       "      <th>AAPL UW Equity</th>\n",
       "      <th>ABBV UN Equity</th>\n",
       "      <th>ABC UN Equity</th>\n",
       "      <th>ABMD UW Equity</th>\n",
       "      <th>ABT UN Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL UW Equity</th>\n",
       "      <th>XLNX UW Equity</th>\n",
       "      <th>XOM UN Equity</th>\n",
       "      <th>XRAY UW Equity</th>\n",
       "      <th>XRX UN Equity</th>\n",
       "      <th>XYL UN Equity</th>\n",
       "      <th>YUM UN Equity</th>\n",
       "      <th>ZBH UN Equity</th>\n",
       "      <th>ZION UW Equity</th>\n",
       "      <th>ZTS UN Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q1</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.99</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0925</td>\n",
       "      <td>-0.030</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.210</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>1.64</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1725</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.56</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Q2</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.35</td>\n",
       "      <td>1.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.035357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>-0.145</td>\n",
       "      <td>0.42</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0975</td>\n",
       "      <td>0.285</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>2.28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.60</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Q3</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050357</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1075</td>\n",
       "      <td>-0.135</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.0325</td>\n",
       "      <td>0.315</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>1.96</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.3200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.64</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Q4</td>\n",
       "      <td>1999</td>\n",
       "      <td>0.32</td>\n",
       "      <td>1.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024643</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0375</td>\n",
       "      <td>-0.080</td>\n",
       "      <td>0.43</td>\n",
       "      <td>...</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>1.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.49</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Q1</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.89</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040585</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1050</td>\n",
       "      <td>-0.045</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.1650</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>-1.48</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.2025</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Quarter  Year  A UN Equity  AAL UW Equity  AAP UN Equity  AAPL UW Equity  \\\n",
       "0      Q1  1999         0.16           0.99            NaN        0.040000   \n",
       "1      Q2  1999         0.35           1.76            NaN        0.035357   \n",
       "2      Q3  1999         0.30           1.86            NaN        0.050357   \n",
       "3      Q4  1999         0.32           1.89            NaN        0.024643   \n",
       "4      Q1  2000         0.29           0.89            NaN        0.040585   \n",
       "\n",
       "   ABBV UN Equity  ABC UN Equity  ABMD UW Equity  ABT UN Equity  ...  \\\n",
       "0             NaN         0.0925          -0.030           0.44  ...   \n",
       "1             NaN         0.1000          -0.145           0.42  ...   \n",
       "2             NaN         0.1075          -0.135           0.30  ...   \n",
       "3             NaN         0.0375          -0.080           0.43  ...   \n",
       "4             NaN         0.1050          -0.045           0.45  ...   \n",
       "\n",
       "   XEL UW Equity  XLNX UW Equity  XOM UN Equity  XRAY UW Equity  \\\n",
       "0           0.34          0.0000          0.210        0.123333   \n",
       "1           0.06          0.0975          0.285        0.133333   \n",
       "2           0.63          0.0325          0.315        0.130000   \n",
       "3           0.43          0.1300          0.600        0.180000   \n",
       "4           0.45          0.1650          0.500        0.140000   \n",
       "\n",
       "   XRX UN Equity  XYL UN Equity  YUM UN Equity  ZBH UN Equity  ZION UW Equity  \\\n",
       "0           1.64            NaN         0.1725            NaN            0.56   \n",
       "1           2.28            NaN         0.2900            NaN            0.60   \n",
       "2           1.96            NaN         0.3200            NaN            0.64   \n",
       "3           1.72            NaN         0.2375            NaN            0.49   \n",
       "4          -1.48            NaN         0.2025            NaN           -0.33   \n",
       "\n",
       "   ZTS UN Equity  \n",
       "0            NaN  \n",
       "1            NaN  \n",
       "2            NaN  \n",
       "3            NaN  \n",
       "4            NaN  \n",
       "\n",
       "[5 rows x 507 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eps_act.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Historic actual EOD**\n",
    "> Though this is not directly related to EPS data, EOD would be an interesting measure to use when generating intriguing visualizations and analyses. Who knows what visuals and conclusions I would arrive to with this measure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historic actual EOD\n",
    "df_eod_act = pd.read_csv(PATH + 'sp-eod-act.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>A UN Equity</th>\n",
       "      <th>AAL UW Equity</th>\n",
       "      <th>AAP UN Equity</th>\n",
       "      <th>AAPL UW Equity</th>\n",
       "      <th>ABBV UN Equity</th>\n",
       "      <th>ABC UN Equity</th>\n",
       "      <th>ABMD UW Equity</th>\n",
       "      <th>ABT UN Equity</th>\n",
       "      <th>ACN UN Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL UW Equity</th>\n",
       "      <th>XLNX UW Equity</th>\n",
       "      <th>XOM UN Equity</th>\n",
       "      <th>XRAY UW Equity</th>\n",
       "      <th>XRX UN Equity</th>\n",
       "      <th>XYL UN Equity</th>\n",
       "      <th>YUM UN Equity</th>\n",
       "      <th>ZBH UN Equity</th>\n",
       "      <th>ZION UW Equity</th>\n",
       "      <th>ZTS UN Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3/31/1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.2835</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.2934</td>\n",
       "      <td>6.250</td>\n",
       "      <td>20.9504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.2813</td>\n",
       "      <td>35.2813</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>140.6214</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.6284</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.5000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6/30/1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.6540</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.1859</td>\n",
       "      <td>6.875</td>\n",
       "      <td>20.3630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>28.6250</td>\n",
       "      <td>38.5625</td>\n",
       "      <td>9.6250</td>\n",
       "      <td>155.6057</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.7297</td>\n",
       "      <td>NaN</td>\n",
       "      <td>63.5000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9/30/1999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.2612</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.7462</td>\n",
       "      <td>7.750</td>\n",
       "      <td>16.4471</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.7656</td>\n",
       "      <td>37.9688</td>\n",
       "      <td>7.5833</td>\n",
       "      <td>110.4883</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.3591</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.1250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>12/31/1999</td>\n",
       "      <td>52.0909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6719</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6843</td>\n",
       "      <td>18.375</td>\n",
       "      <td>16.2513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>45.4688</td>\n",
       "      <td>40.2813</td>\n",
       "      <td>7.8750</td>\n",
       "      <td>59.7723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.9434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.1875</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/31/2000</td>\n",
       "      <td>70.0721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6388</td>\n",
       "      <td>20.250</td>\n",
       "      <td>15.7478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.8125</td>\n",
       "      <td>38.9063</td>\n",
       "      <td>9.4583</td>\n",
       "      <td>68.4994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.6250</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 506 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  A UN Equity  AAL UW Equity  AAP UN Equity  AAPL UW Equity  \\\n",
       "0   3/31/1999          NaN            NaN            NaN          1.2835   \n",
       "1   6/30/1999          NaN            NaN            NaN          1.6540   \n",
       "2   9/30/1999          NaN            NaN            NaN          2.2612   \n",
       "3  12/31/1999      52.0909            NaN            NaN          3.6719   \n",
       "4   3/31/2000      70.0721            NaN            NaN          4.8504   \n",
       "\n",
       "   ABBV UN Equity  ABC UN Equity  ABMD UW Equity  ABT UN Equity  \\\n",
       "0             NaN         8.2934           6.250        20.9504   \n",
       "1             NaN         6.1859           6.875        20.3630   \n",
       "2             NaN         5.7462           7.750        16.4471   \n",
       "3             NaN         3.6843          18.375        16.2513   \n",
       "4             NaN         3.6388          20.250        15.7478   \n",
       "\n",
       "   ACN UN Equity  ...  XEL UW Equity  XLNX UW Equity  XOM UN Equity  \\\n",
       "0            NaN  ...            NaN         20.2813        35.2813   \n",
       "1            NaN  ...            NaN         28.6250        38.5625   \n",
       "2            NaN  ...            NaN         32.7656        37.9688   \n",
       "3            NaN  ...            NaN         45.4688        40.2813   \n",
       "4            NaN  ...            NaN         82.8125        38.9063   \n",
       "\n",
       "   XRAY UW Equity  XRX UN Equity  XYL UN Equity  YUM UN Equity  ZBH UN Equity  \\\n",
       "0          7.7500       140.6214            NaN        12.6284            NaN   \n",
       "1          9.6250       155.6057            NaN         9.7297            NaN   \n",
       "2          7.5833       110.4883            NaN         7.3591            NaN   \n",
       "3          7.8750        59.7723            NaN         6.9434            NaN   \n",
       "4          9.4583        68.4994            NaN         5.5839            NaN   \n",
       "\n",
       "   ZION UW Equity  ZTS UN Equity  \n",
       "0         66.5000            NaN  \n",
       "1         63.5000            NaN  \n",
       "2         55.1250            NaN  \n",
       "3         59.1875            NaN  \n",
       "4         41.6250            NaN  \n",
       "\n",
       "[5 rows x 506 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eod_act.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Historic forecasted EPS 3 months prior**\n",
    "> Instead of using forecast data collected at the beginning of the fiscal period, this feature contains EPS data projected 3 months before the current fiscal period. This is an interesting metric to see how differently forecasters make their predictions at different times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#historic forecasted EPS 3-months prior\n",
    "df_eps_fc_terms = pd.read_csv(PATH + 'sp-eps-fc-terms.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Forecast Made</th>\n",
       "      <th>Term Forecasted</th>\n",
       "      <th>A UN Equity</th>\n",
       "      <th>AAL UW Equity</th>\n",
       "      <th>AAP UN Equity</th>\n",
       "      <th>AAPL UW Equity</th>\n",
       "      <th>ABBV UN Equity</th>\n",
       "      <th>ABC UN Equity</th>\n",
       "      <th>ABMD UW Equity</th>\n",
       "      <th>ABT UN Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL UW Equity</th>\n",
       "      <th>XLNX UW Equity</th>\n",
       "      <th>XOM UN Equity</th>\n",
       "      <th>XRAY UW Equity</th>\n",
       "      <th>XRX UN Equity</th>\n",
       "      <th>XYL UN Equity</th>\n",
       "      <th>YUM UN Equity</th>\n",
       "      <th>ZBH UN Equity</th>\n",
       "      <th>ZION UW Equity</th>\n",
       "      <th>ZTS UN Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10/1/1999</td>\n",
       "      <td>00Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.030</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.466</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.143</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.140</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.144</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1/1/2000</td>\n",
       "      <td>00Q2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.026</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.437</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.168</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.153</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.184</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.790</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4/1/2000</td>\n",
       "      <td>00Q3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.425</td>\n",
       "      <td>0.149</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.218</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.803</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7/1/2000</td>\n",
       "      <td>00Q4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.032</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.18</td>\n",
       "      <td>0.477</td>\n",
       "      <td>...</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.211</td>\n",
       "      <td>0.487</td>\n",
       "      <td>0.200</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.244</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.777</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9/1/2000</td>\n",
       "      <td>01Q1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.09</td>\n",
       "      <td>0.495</td>\n",
       "      <td>...</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.259</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.158</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.178</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.750</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 507 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Forecast Made Term Forecasted  A UN Equity  AAL UW Equity  AAP UN Equity  \\\n",
       "0     10/1/1999            00Q1          NaN            NaN            NaN   \n",
       "1      1/1/2000            00Q2          NaN            NaN            NaN   \n",
       "2      4/1/2000            00Q3          NaN            NaN            NaN   \n",
       "3      7/1/2000            00Q4          NaN            NaN            NaN   \n",
       "4      9/1/2000            01Q1          NaN            NaN            NaN   \n",
       "\n",
       "   AAPL UW Equity  ABBV UN Equity  ABC UN Equity  ABMD UW Equity  \\\n",
       "0           0.030             NaN            NaN             NaN   \n",
       "1           0.026             NaN            NaN             NaN   \n",
       "2           0.029             NaN            NaN             NaN   \n",
       "3           0.032             NaN            NaN           -0.18   \n",
       "4           0.041             NaN            NaN           -0.09   \n",
       "\n",
       "   ABT UN Equity  ...  XEL UW Equity  XLNX UW Equity  XOM UN Equity  \\\n",
       "0          0.466  ...            NaN           0.143          0.398   \n",
       "1          0.437  ...            NaN           0.168          0.378   \n",
       "2          0.414  ...           0.84           0.189          0.425   \n",
       "3          0.477  ...           0.53           0.211          0.487   \n",
       "4          0.495  ...           0.40           0.259          0.475   \n",
       "\n",
       "   XRAY UW Equity  XRX UN Equity  XYL UN Equity  YUM UN Equity  ZBH UN Equity  \\\n",
       "0           0.140            NaN            NaN          0.144            NaN   \n",
       "1           0.153            NaN            NaN          0.184            NaN   \n",
       "2           0.149            NaN            NaN          0.218            NaN   \n",
       "3           0.200            NaN            NaN          0.244            NaN   \n",
       "4           0.158            NaN            NaN          0.178            NaN   \n",
       "\n",
       "   ZION UW Equity  ZTS UN Equity  \n",
       "0           0.777            NaN  \n",
       "1           0.790            NaN  \n",
       "2           0.803            NaN  \n",
       "3           0.777            NaN  \n",
       "4           0.750            NaN  \n",
       "\n",
       "[5 rows x 507 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eps_fc_terms.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B) Assess <a id = \"assess\"></a>\n",
    "\n",
    "> The following DataFrames contain data for each firm across various dates. To account for all firm averages, my goal is to generate a CSV file where each row contains the firm average, with the features as columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dfs = {'eps_fcast' : df_eps_fc,\n",
    "           'eps_actual' : df_eps_act,\n",
    "           'eod_actual' : df_eod_act,\n",
    "           'eps_fcast_terms' : df_eps_fc_terms}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CHECK FOR MISSING DATA***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast (84, 506)\n",
      "eps_actual (84, 507)\n",
      "eod_actual (84, 506)\n",
      "eps_fcast_terms (80, 507)\n"
     ]
    }
   ],
   "source": [
    "for key, df in dict_dfs.items():\n",
    "    print(key, df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***We need to make sure the number of firms in each DataFrame is consistent.***\n",
    "\n",
    "---\n",
    "\n",
    "**Observation 1:** for `eps_fcast`, there are 505 firms encompassing 84 quarterly fiscal periods since 1999.\n",
    "\n",
    "> There are 506 columns: 1 column being `Term Forecast`, the rest firm names.\n",
    "\n",
    "**Observation 2:** for `eps_actual`, there are 505 firms encompassing 84 quarterly fiscal periods since 1999.\n",
    "\n",
    "> There are 507 columns: 2 columns being `Quarter` and `Year`, the rest firm names.\n",
    "\n",
    "**Observation 3:** for `eod_actual`, there are 505 firms encompassing 84 quarterly calendar periods since 1999.\n",
    "\n",
    "> There are 506 columns: 1 column being `date`, the rest firm names.\n",
    "\n",
    "**Observation 4:** for `eps_fcast_terms`, there are 505 firms encompassing 80 quarterly calendar periods since 1999.\n",
    "\n",
    "> There are 507 columns: 2 columns being `Forecast Made` and `Term Forecasted`, the rest firm names.\n",
    " \n",
    "Since there are only 80 quarterly calendar periods, that ***implies an entire year is missing.***\n",
    "\n",
    "**Observation 5:** For `eps_fcast`, `eps_actual`, and `eod_actual`, since there are 4 quarters in a year, 84 quarterly forecast periods equate to 21 years. This is correct since we are analyzing the years from 1999 until the end of 2019.\n",
    "\n",
    "### Most importantly, the number of firms across all DataFrames is consistent.\n",
    "\n",
    "----\n",
    "\n",
    "***Check which year is missing from `eps_fcast_terms`***.\n",
    "\n",
    "> Each **Term Forecasted** entry under `eps_fcast_terms` records the year with 2 digits, so Quarter 1 of the year 2000 becomes 00Q1.\n",
    "- isolate the first 2 characters to get the year\n",
    "- join a '20' in front of the string so 00 becomes 2000\n",
    "- list the number of unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2000',\n",
       " '2001',\n",
       " '2002',\n",
       " '2003',\n",
       " '2004',\n",
       " '2005',\n",
       " '2006',\n",
       " '2007',\n",
       " '2008',\n",
       " '2009',\n",
       " '2010',\n",
       " '2011',\n",
       " '2012',\n",
       " '2013',\n",
       " '2014',\n",
       " '2015',\n",
       " '2016',\n",
       " '2017',\n",
       " '2018',\n",
       " '2019']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iterate over all years in eps_fcast_terms, append '20' in front of string\n",
    "list(map(lambda x: '20' + x, df_eps_fc_terms['Term Forecasted'].str[:2].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation**: The year 1999 is missing from `df_eps_fc_terms`. This makes sense because the start of the forecasting period would be in the last quarter of 1999, which is October. \n",
    "\n",
    "---\n",
    "\n",
    "***CHECK NULLS***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# NaN in eps_fcast: 7055\n",
      "# NaN in eps_actual: 5021\n",
      "# NaN in eod_actual: 6921\n",
      "# NaN in eps_fcast_terms: 7080\n"
     ]
    }
   ],
   "source": [
    "for key, df in dict_dfs.items():\n",
    "    #display (row, column) per DataFrame\n",
    "    print('# NaN in {}: {}'.format(key, df.isna().sum().sum()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** All four DataSets contain null values.\n",
    "> In order to combat this, we'll have to look at both the **number of rows** and **number of columns** with missing data, separately. This way, we can isolate which firms and/or time periods contain complete or incomplete data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast has 82 time periods containing missing data, out of 84 total rows.\n",
      "eps_actual has 84 time periods containing missing data, out of 84 total rows.\n",
      "eod_actual has 83 time periods containing missing data, out of 84 total rows.\n",
      "eps_fcast_terms has 80 time periods containing missing data, out of 80 total rows.\n"
     ]
    }
   ],
   "source": [
    "#check rows for missing data\n",
    "for key, df in dict_dfs.items():\n",
    "    num_rows_missing = df.isna().sum().max()\n",
    "    print('{} has {} time periods containing missing data, out of {} total rows.'.format(key, num_rows_missing, df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_eps_fc.columns[df_eps_fc.isnull().any()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast has 254 firms containing missing data, out of 506 total columns.\n",
      "eps_actual has 432 firms containing missing data, out of 507 total columns.\n",
      "eod_actual has 505 firms containing missing data, out of 506 total columns.\n",
      "eps_fcast_terms has 340 firms containing missing data, out of 507 total columns.\n"
     ]
    }
   ],
   "source": [
    "#check columns for missing data\n",
    "for key, df in dict_dfs.items():\n",
    "    cols_missing = df.columns[df.isnull().any()]\n",
    "    num_cols_missing = len(cols_missing)\n",
    "    print('{} has {} firms containing missing data, out of {} total columns.'\n",
    "         .format(key, num_cols_missing, df.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation 1:** The only two datasets with incomplete data for all time periods are **actual EPS** and **forecasted EPS 3 months prior.**\n",
    "\n",
    "> To address this problem, it'd be helpful to isolate the time period ranges for the datasets with incomplete data by row, **forecasted EPS** and **actual EOD price.**\n",
    "\n",
    "**Observation 2:** For all datasets, all firms contain incomplete data across all time periods.\n",
    "> This is expected, as analyzing financial history spanning over 20 years will naturally be rife with missing and inaccurate data. The ***good news is that `eps_fcast`, `eps_actual`, and `eps_fcast_terms` are the most complete, while `eod_actual` contains the most amount of missing data.***\n",
    "\n",
    "\n",
    "**Moving forward, we need to make sure that these inconsistencies won't clash with our analysis.**\n",
    "> **My approach:** instead of looking at rows and columns ***with*** missing data, we'll be looking at rows and columns that ***are all missing data.***\n",
    "\n",
    "I figured that if there is some missing data here and there scattered throughout the matrix, then that should not skew our analysis too much.\n",
    "\n",
    "However, if there a significant amount of rows/columns that are entirely empty, then we ***might have to get ready to drop some dates and firms from our data overall.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast \n",
      " False    84\n",
      "dtype: int64\n",
      "eps_actual \n",
      " False    84\n",
      "dtype: int64\n",
      "eod_actual \n",
      " False    84\n",
      "dtype: int64\n",
      "eps_fcast_terms \n",
      " False    80\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for empty rows, return False if row contains at least one non-null value, True if all are null\n",
    "for key, df in dict_dfs.items():\n",
    "    cols_check = df.columns\n",
    "    num_empty_rows = (df[cols_check].isnull().apply(lambda x: all(x), axis = 1)).value_counts()\n",
    "    print(key, '\\n', num_empty_rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** All datasets do not contain empty rows.\n",
    "> This is good news, since we can rely on the firms' averages per row instead of having to drop or limit time periods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast \n",
      " False    506\n",
      "dtype: int64\n",
      "eps_actual \n",
      " False    506\n",
      "True       1\n",
      "dtype: int64\n",
      "eod_actual \n",
      " False    506\n",
      "dtype: int64\n",
      "eps_fcast_terms \n",
      " False    506\n",
      "True       1\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#check for empty columns, return False if column contains at least one non-null value, True if all are null\n",
    "for key, df in dict_dfs.items():\n",
    "    cols_check = df.columns\n",
    "    num_empty_cols = df[cols_check].isnull().apply(lambda x: all(x), axis = 0).value_counts()\n",
    "    print(key, '\\n', num_empty_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** `eps_actual` and `eps_fcast_terms` are the only datasets that have an empty column.\n",
    "> Let's isolate and look at the singular empty column for both DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create function to return an array of column names containing empty data\n",
    "def comb_cols(df):\n",
    "    empty_cols = []\n",
    "    for column in df:\n",
    "        if df[column].isnull().all():\n",
    "            empty_cols.append(column)\n",
    "            \n",
    "    return empty_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In eps_act, the firm ['AMCR UN Equity'] has no data.\n",
      "In eps_fc_terms, the firm ['AMCR UN Equity'] has no data.\n"
     ]
    }
   ],
   "source": [
    "#comb datasets for empty columns\n",
    "print('In eps_act, the firm {} has no data.'.format(comb_cols(df_eps_act)))\n",
    "print('In eps_fc_terms, the firm {} has no data.'.format(comb_cols(df_eps_fc_terms)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** The same firm in both datasets is empty of data.\n",
    "> Though this is an annoying error to deal with, it still is to our advantage that both datasets ***share one firm*** in common for missing data. This way, we don't have to worry about dropping two entire firms.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CHECK DUPLICATE DATA***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast 0\n",
      "eps_actual 0\n",
      "eod_actual 0\n",
      "eps_fcast_terms 0\n"
     ]
    }
   ],
   "source": [
    "#check for duplicate data across all rows and columns\n",
    "for key, df in dict_dfs.items():\n",
    "    print(key, df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** For all datasets, there are ***no duplicate data.*** This is good news!\n",
    "\n",
    "**Next, I will check for duplicated firm names.** Although the presence of duplicated firm names will inherently imply duplicated data, sometimes data gets dispersed in weird, unexpected ways, especially when dealing with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eps_fcast 0\n",
      "eps_actual 0\n",
      "eod_actual 0\n",
      "eps_fcast_terms 0\n"
     ]
    }
   ],
   "source": [
    "#check for duplicated firm names\n",
    "for key, df in dict_dfs.items():\n",
    "    print(key, df.columns.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** For all datasets, there are ***no duplicate firm names.*** This is also good news.\n",
    "> There is no need to dedupe our data during the cleaning stage.\n",
    "\n",
    "***CHECK DATA TYPES***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***REORDER COLUMNS (IF APPLICABLE)***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "# CUTOFF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** There are 505 firms encompassing 84 calendar periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observations:** \n",
    "\n",
    "- there is no calendar period that's empty of data for all firms.\n",
    "- there is no firm that's empty of data for all calendar periods.\n",
    "\n",
    "**Therefore, all calendar periods and firms have data for historical end of day stock price.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#count how many rows have isolated data\n",
    "df_eps_act.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** There is no duplicated data among all firms for all calendar periods in `df_eod`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count number of repeated firm names\n",
    "df_eod.columns.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>A UN Equity</th>\n",
       "      <th>AAL UW Equity</th>\n",
       "      <th>AAP UN Equity</th>\n",
       "      <th>AAPL UW Equity</th>\n",
       "      <th>ABBV UN Equity</th>\n",
       "      <th>ABC UN Equity</th>\n",
       "      <th>ABMD UW Equity</th>\n",
       "      <th>ABT UN Equity</th>\n",
       "      <th>ACN UN Equity</th>\n",
       "      <th>...</th>\n",
       "      <th>XEL UW Equity</th>\n",
       "      <th>XLNX UW Equity</th>\n",
       "      <th>XOM UN Equity</th>\n",
       "      <th>XRAY UW Equity</th>\n",
       "      <th>XRX UN Equity</th>\n",
       "      <th>XYL UN Equity</th>\n",
       "      <th>YUM UN Equity</th>\n",
       "      <th>ZBH UN Equity</th>\n",
       "      <th>ZION UW Equity</th>\n",
       "      <th>ZTS UN Equity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>12/31/2018</td>\n",
       "      <td>67.4600</td>\n",
       "      <td>32.11</td>\n",
       "      <td>157.460</td>\n",
       "      <td>157.7400</td>\n",
       "      <td>92.19</td>\n",
       "      <td>74.4000</td>\n",
       "      <td>325.04</td>\n",
       "      <td>72.3300</td>\n",
       "      <td>141.01</td>\n",
       "      <td>...</td>\n",
       "      <td>49.27</td>\n",
       "      <td>85.1700</td>\n",
       "      <td>68.1900</td>\n",
       "      <td>37.2100</td>\n",
       "      <td>19.7600</td>\n",
       "      <td>66.72</td>\n",
       "      <td>91.9200</td>\n",
       "      <td>103.72</td>\n",
       "      <td>40.740</td>\n",
       "      <td>85.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6/30/2003</td>\n",
       "      <td>13.1722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.300</td>\n",
       "      <td>1.3657</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.8232</td>\n",
       "      <td>5.47</td>\n",
       "      <td>19.5843</td>\n",
       "      <td>18.09</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.3100</td>\n",
       "      <td>35.9100</td>\n",
       "      <td>20.4500</td>\n",
       "      <td>27.9003</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.6276</td>\n",
       "      <td>45.05</td>\n",
       "      <td>50.610</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>6/30/2016</td>\n",
       "      <td>44.3600</td>\n",
       "      <td>28.31</td>\n",
       "      <td>161.630</td>\n",
       "      <td>95.6000</td>\n",
       "      <td>61.91</td>\n",
       "      <td>79.3200</td>\n",
       "      <td>109.29</td>\n",
       "      <td>39.3100</td>\n",
       "      <td>113.29</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>46.1300</td>\n",
       "      <td>93.7400</td>\n",
       "      <td>62.0400</td>\n",
       "      <td>25.0023</td>\n",
       "      <td>44.65</td>\n",
       "      <td>59.6240</td>\n",
       "      <td>120.38</td>\n",
       "      <td>25.130</td>\n",
       "      <td>47.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6/30/2005</td>\n",
       "      <td>15.5102</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43.033</td>\n",
       "      <td>5.2586</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.7747</td>\n",
       "      <td>8.55</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>22.67</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5000</td>\n",
       "      <td>57.4700</td>\n",
       "      <td>27.0000</td>\n",
       "      <td>36.3310</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.7242</td>\n",
       "      <td>76.17</td>\n",
       "      <td>73.530</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3/31/2000</td>\n",
       "      <td>70.0721</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.8504</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6388</td>\n",
       "      <td>20.25</td>\n",
       "      <td>15.7478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>82.8125</td>\n",
       "      <td>38.9063</td>\n",
       "      <td>9.4583</td>\n",
       "      <td>68.4994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.5839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>41.625</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>9/28/2001</td>\n",
       "      <td>13.1722</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.1079</td>\n",
       "      <td>NaN</td>\n",
       "      <td>17.2114</td>\n",
       "      <td>17.47</td>\n",
       "      <td>23.2049</td>\n",
       "      <td>12.75</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.5300</td>\n",
       "      <td>39.4000</td>\n",
       "      <td>15.3133</td>\n",
       "      <td>20.4181</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.0503</td>\n",
       "      <td>27.75</td>\n",
       "      <td>53.660</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>9/28/2018</td>\n",
       "      <td>70.5400</td>\n",
       "      <td>41.33</td>\n",
       "      <td>168.330</td>\n",
       "      <td>225.7400</td>\n",
       "      <td>94.58</td>\n",
       "      <td>92.2200</td>\n",
       "      <td>449.75</td>\n",
       "      <td>73.3600</td>\n",
       "      <td>170.20</td>\n",
       "      <td>...</td>\n",
       "      <td>47.21</td>\n",
       "      <td>80.1700</td>\n",
       "      <td>85.0200</td>\n",
       "      <td>37.7400</td>\n",
       "      <td>26.9800</td>\n",
       "      <td>79.87</td>\n",
       "      <td>90.9100</td>\n",
       "      <td>131.47</td>\n",
       "      <td>50.150</td>\n",
       "      <td>91.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>6/29/2018</td>\n",
       "      <td>61.8400</td>\n",
       "      <td>37.96</td>\n",
       "      <td>135.700</td>\n",
       "      <td>185.1100</td>\n",
       "      <td>92.65</td>\n",
       "      <td>85.2700</td>\n",
       "      <td>409.05</td>\n",
       "      <td>60.9900</td>\n",
       "      <td>163.59</td>\n",
       "      <td>...</td>\n",
       "      <td>45.68</td>\n",
       "      <td>65.2600</td>\n",
       "      <td>82.7300</td>\n",
       "      <td>43.7700</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>67.38</td>\n",
       "      <td>78.2200</td>\n",
       "      <td>111.44</td>\n",
       "      <td>52.690</td>\n",
       "      <td>85.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>3/30/2007</td>\n",
       "      <td>24.0913</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.550</td>\n",
       "      <td>13.2729</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.5927</td>\n",
       "      <td>13.66</td>\n",
       "      <td>26.6988</td>\n",
       "      <td>38.54</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.7300</td>\n",
       "      <td>75.4500</td>\n",
       "      <td>32.7500</td>\n",
       "      <td>44.4983</td>\n",
       "      <td>NaN</td>\n",
       "      <td>20.7663</td>\n",
       "      <td>85.41</td>\n",
       "      <td>84.520</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>9/29/2006</td>\n",
       "      <td>22.0256</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.940</td>\n",
       "      <td>11.0043</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.9296</td>\n",
       "      <td>14.79</td>\n",
       "      <td>23.2347</td>\n",
       "      <td>31.71</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>21.9500</td>\n",
       "      <td>67.1000</td>\n",
       "      <td>30.1100</td>\n",
       "      <td>40.9943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18.7134</td>\n",
       "      <td>67.50</td>\n",
       "      <td>79.810</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 506 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          date  A UN Equity  AAL UW Equity  AAP UN Equity  AAPL UW Equity  \\\n",
       "79  12/31/2018      67.4600          32.11        157.460        157.7400   \n",
       "17   6/30/2003      13.1722            NaN         20.300          1.3657   \n",
       "69   6/30/2016      44.3600          28.31        161.630         95.6000   \n",
       "25   6/30/2005      15.5102            NaN         43.033          5.2586   \n",
       "4    3/31/2000      70.0721            NaN            NaN          4.8504   \n",
       "10   9/28/2001      13.1722            NaN            NaN          1.1079   \n",
       "78   9/28/2018      70.5400          41.33        168.330        225.7400   \n",
       "77   6/29/2018      61.8400          37.96        135.700        185.1100   \n",
       "32   3/30/2007      24.0913            NaN         38.550         13.2729   \n",
       "30   9/29/2006      22.0256            NaN         32.940         11.0043   \n",
       "\n",
       "    ABBV UN Equity  ABC UN Equity  ABMD UW Equity  ABT UN Equity  \\\n",
       "79           92.19        74.4000          325.04        72.3300   \n",
       "17             NaN        16.8232            5.47        19.5843   \n",
       "69           61.91        79.3200          109.29        39.3100   \n",
       "25             NaN        16.7747            8.55        23.4500   \n",
       "4              NaN         3.6388           20.25        15.7478   \n",
       "10             NaN        17.2114           17.47        23.2049   \n",
       "78           94.58        92.2200          449.75        73.3600   \n",
       "77           92.65        85.2700          409.05        60.9900   \n",
       "32             NaN        25.5927           13.66        26.6988   \n",
       "30             NaN        21.9296           14.79        23.2347   \n",
       "\n",
       "    ACN UN Equity  ...  XEL UW Equity  XLNX UW Equity  XOM UN Equity  \\\n",
       "79         141.01  ...          49.27         85.1700        68.1900   \n",
       "17          18.09  ...            NaN         25.3100        35.9100   \n",
       "69         113.29  ...            NaN         46.1300        93.7400   \n",
       "25          22.67  ...            NaN         25.5000        57.4700   \n",
       "4             NaN  ...            NaN         82.8125        38.9063   \n",
       "10          12.75  ...            NaN         23.5300        39.4000   \n",
       "78         170.20  ...          47.21         80.1700        85.0200   \n",
       "77         163.59  ...          45.68         65.2600        82.7300   \n",
       "32          38.54  ...            NaN         25.7300        75.4500   \n",
       "30          31.71  ...            NaN         21.9500        67.1000   \n",
       "\n",
       "    XRAY UW Equity  XRX UN Equity  XYL UN Equity  YUM UN Equity  \\\n",
       "79         37.2100        19.7600          66.72        91.9200   \n",
       "17         20.4500        27.9003            NaN        10.6276   \n",
       "69         62.0400        25.0023          44.65        59.6240   \n",
       "25         27.0000        36.3310            NaN        18.7242   \n",
       "4           9.4583        68.4994            NaN         5.5839   \n",
       "10         15.3133        20.4181            NaN         7.0503   \n",
       "78         37.7400        26.9800          79.87        90.9100   \n",
       "77         43.7700        24.0000          67.38        78.2200   \n",
       "32         32.7500        44.4983            NaN        20.7663   \n",
       "30         30.1100        40.9943            NaN        18.7134   \n",
       "\n",
       "    ZBH UN Equity  ZION UW Equity  ZTS UN Equity  \n",
       "79         103.72          40.740          85.54  \n",
       "17          45.05          50.610            NaN  \n",
       "69         120.38          25.130          47.46  \n",
       "25          76.17          73.530            NaN  \n",
       "4             NaN          41.625            NaN  \n",
       "10          27.75          53.660            NaN  \n",
       "78         131.47          50.150          91.56  \n",
       "77         111.44          52.690          85.19  \n",
       "32          85.41          84.520            NaN  \n",
       "30          67.50          79.810            NaN  \n",
       "\n",
       "[10 rows x 506 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_eod_act.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Observation:** There are no duplicated firms in `df_eod`.\n",
    "\n",
    "### Quality\n",
    "\n",
    "**Missing Data**\n",
    "\n",
    "-  `df_eps_fc_terms` is missing the year 1999.\n",
    "- `df_eps_act` and `df_eps_fc_act` have one firm with empty data.\n",
    "--- \n",
    "\n",
    "- no recorded 20-year averages for each dataset.\n",
    "- firm names across both DataFrames are capitalized\n",
    "\n",
    "\n",
    "### Tidiness\n",
    "\n",
    "- forecast + actual EPS DataFrames need to be merged with firm names transposed into rows\n",
    "- all firm averages need to be joined in a new DataFrame\n",
    "\n",
    "## C) Cleaning\n",
    "\n",
    "### Code\n",
    "\n",
    "\n",
    "### Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***CHECK THAT OUR DATA IS CONSISTENT WITH THE ORIGINAL DATA***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# III) Store Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
